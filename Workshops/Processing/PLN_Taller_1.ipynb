{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlqZ-X54XkMp"
      },
      "source": [
        "#**PLN - Universidad Nacional de Colombia**\n",
        "\n",
        "##Taller 1\n",
        "###Procesamiento: NLTK,Spacy,Tokenización, normlización, Expresiones Regulares\n",
        "###Profesora Elizabeth León Guzmán\n",
        "###Estudiante Francisco J. Salamanca\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCwWTUeDWMEm"
      },
      "source": [
        "### 1. Cargar archivo\n",
        " Cargar el archivo twitter.tsv trabajado en clase (notebook 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w4bbjpQgu3L_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Cargar archivo\n",
        "data = pd.read_csv(\"twitter.tsv\", delimiter = \"\\t\", quoting = 3)\n",
        "del data[\"Unnamed: 0\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uwEia7TUu68F",
        "outputId": "302e13d8-65b6-4222-cc53-05f0e4ca1574"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              id_tweet           created_at     user_name  \\\n",
              "0  1046764647116951553  2018-10-01 09:11:54      dpazmino   \n",
              "1  1046833427301978112  2018-10-01 13:45:12        Citytv   \n",
              "2  1046876307110412289  2018-10-01 16:35:36  RodrigoMutis   \n",
              "3  1046904276692426754  2018-10-01 18:26:44      Luigi32H   \n",
              "4  1047149277330460673  2018-10-02 10:40:17    dhidalgo65   \n",
              "\n",
              "                                                text  \n",
              "0  #lamadre para esos usuarios de @TransMilenio q...  \n",
              "1  8 años de un patio taller del SITP 'provisiona...  \n",
              "2  La @CAR_Cundi de manera antidemocrática y arbi...  \n",
              "3  @TransMilenio manden buses acaba de llegar uno...  \n",
              "4  .@Bogota sigue disminuyendo el número de muert...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f411408f-ba38-4ea2-bfcb-b256a4f7ab19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_tweet</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1046764647116951553</td>\n",
              "      <td>2018-10-01 09:11:54</td>\n",
              "      <td>dpazmino</td>\n",
              "      <td>#lamadre para esos usuarios de @TransMilenio q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1046833427301978112</td>\n",
              "      <td>2018-10-01 13:45:12</td>\n",
              "      <td>Citytv</td>\n",
              "      <td>8 años de un patio taller del SITP 'provisiona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1046876307110412289</td>\n",
              "      <td>2018-10-01 16:35:36</td>\n",
              "      <td>RodrigoMutis</td>\n",
              "      <td>La @CAR_Cundi de manera antidemocrática y arbi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1046904276692426754</td>\n",
              "      <td>2018-10-01 18:26:44</td>\n",
              "      <td>Luigi32H</td>\n",
              "      <td>@TransMilenio manden buses acaba de llegar uno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1047149277330460673</td>\n",
              "      <td>2018-10-02 10:40:17</td>\n",
              "      <td>dhidalgo65</td>\n",
              "      <td>.@Bogota sigue disminuyendo el número de muert...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f411408f-ba38-4ea2-bfcb-b256a4f7ab19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f411408f-ba38-4ea2-bfcb-b256a4f7ab19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f411408f-ba38-4ea2-bfcb-b256a4f7ab19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-82529267-dc5b-485b-b0fb-9d7cd3b87731\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82529267-dc5b-485b-b0fb-9d7cd3b87731')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-82529267-dc5b-485b-b0fb-9d7cd3b87731 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"id_tweet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9047080572059108,\n        \"min\": 1046764647116951553,\n        \"max\": 1079748535149563914,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          1062864237180211200,\n          1069990341967785987,\n          1070013605351956480\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2018-11-14 19:25:55\",\n          \"2018-12-04 11:22:31\",\n          \"2018-12-04 12:54:58\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 850,\n        \"samples\": [\n          \"AndreT_Perez\",\n          \"Orleyes\",\n          \"Danieeelaaa_\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"@yoresongo Siempre.\",\n          \"Mi primo zuleta_fabio el mejor humorista costumbrista.. en Bogot\\u00e1, Colombia https://t.co/oMxnn2vMU7\",\n          \"@EnvigadoFC es un buen equipo. Para la B \\ud83e\\udd37\\ud83c\\udffb\\u200d\\u2642\\ufe0f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Ver los primeros 5 registros\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAXsYlTxu8uj",
        "outputId": "c06f1d8c-1cd9-4948-f00f-9691f8ac717b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tid_tweet\tcreated_at\tuser_name\ttext\n",
            "0\t1046764647116951553\t2018-10-01 09:11:54\tdpazmino\t#lamadre para esos usuarios de @TransMilenio que cuando llevan morral no lo ponen en la parte de adelante y hacen estorbo #BogotáHumana\n",
            "1\t1046833427301978112\t2018-10-01 13:45:12\tCitytv\t8 años de un patio taller del SITP 'provisional' ►https://t.co/l9BvjSUTI2 https://t.co/NCVKTkaeTE\n",
            "2\t1046876307110412289\t2018-10-01 16:35:36\tRodrigoMutis\tLa @CAR_Cundi de manera antidemocrática y arbitraria le impide a la @ReservaVDHammen hacer parte de la discusión sobre la Reserva van der Hammen, como vocero de la veeduría pido solidaridad para denunciar tal atropello\n",
            "3\t1046904276692426754\t2018-10-01 18:26:44\tLuigi32H\t@TransMilenio manden buses acaba de llegar uno pero lleno. Otra media hora?\n",
            "4\t1047149277330460673\t2018-10-02 10:40:17\tdhidalgo65\t.@Bogota sigue disminuyendo el número de muertes en el tráfico (4%  enero-agosto 2018 respecto al mismo periodo de 2017)Importante reducción en peatones Estabilidad en motociclistas @Bocarejo_JP Segumos reforzando #VisiónCeroBOG, gestión de velocidad https://t.co/gEVeESGXrc\n",
            "5\t1047199536978911232\t2018-10-02 14:00:00\tBogota\t#NoOlvides 🧐 que las rutas alimentadoras 2-11 Andalucía y 13-13 Resurrección 🚌 ajustaron sus recorridos para que más usuarios se vean beneficiados.https://t.co/KTvshvAliv\n",
            "6\t1047207138886656002\t2018-10-02 14:30:12\tsitpbogota\tRuta P500 (Aeropuerto – Centro Andino) - subete al #SITP https://t.co/Ul5JXdgu2S\n"
          ]
        }
      ],
      "source": [
        "#Ver los ultimos 8 registros\n",
        "!head -8 twitter.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6pSmHnMWWpA"
      },
      "source": [
        "###2. Tokenizar\n",
        "Implementar una función para tokenizar considerando los siguientes casos:\n",
        "\n",
        "*   Dividir tokens por espacios, “tab”, y “enters”\n",
        "\n",
        "  Ej: ' this is a tweet ' -> 'this', 'is', 'a', 'tweet\n",
        "*   Dividir por emoticones:\n",
        "\n",
        "  Ej:  haha 😂😂! -> 'haha', '😂😂', '!'\n",
        "\n",
        "\n",
        "*   NO dividir hashtags\n",
        "\n",
        "    Ej: #don'tSplit\n",
        "*   Separar signos de puntuación del texto (tokesn individuales):\n",
        "\n",
        "    Ej: 'hey!' -> 'hey', '!'\n",
        "\n",
        "\n",
        "*  Separar “Contractions” usando el “apostrophe”:\n",
        "\n",
        "  Ej: \"that's fine\" -> 'that', \"'s\", 'fine'\n",
        "\n",
        "  Ej: \"don't do that\" -> 'do', \"n't\", 'do', 'that'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tSU64GaD48s2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "  # Define a regex pattern to match emojis\n",
        "  emoji_pattern = re.compile(\n",
        "      \"[\"\n",
        "      \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "      \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "      \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "      \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "      \"\\U00002702-\\U000027B0\"\n",
        "      \"\\U000024C2-\\U0001F251\"\n",
        "      \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  # Replace emojis with spaces around them to ensure splitting\n",
        "  text_with_spaces_around_emojis = emoji_pattern.sub(r' \\g<0> ', text)\n",
        "\n",
        "  # Pattern to not split hashtags, separate punctuation and contractions, and split by whitespace otherwise\n",
        "  # This pattern prioritizes matching hashtags, then contractions, then punctuation (including quotes), and finally words or other non-whitespace characters.\n",
        "  tokenizer_pattern = re.compile(r\"(#\\w+)|(\\w+'\\w+)|([.,!?;:\\\"'])|(\\S+)\")\n",
        "\n",
        "\n",
        "  # The findall method returns a list of tuples, where each tuple contains the matches for the capturing groups.\n",
        "  # We need to flatten this list of tuples into a single list of tokens, keeping only the non-empty matches.\n",
        "  tokens = [item for sublist in tokenizer_pattern.findall(text_with_spaces_around_emojis) for item in sublist if item]\n",
        "\n",
        "  # Add specific handling for splitting contractions like \"don't\" and \"that's\"\n",
        "  # This is a post-processing step after the initial regex split\n",
        "  processed_tokens = []\n",
        "  for token in tokens:\n",
        "      if \"'\" in token and re.match(r\"\\w+'\\w+\", token):\n",
        "          # Split contractions like \"that's\" and \"don't\"\n",
        "          match = re.match(r\"(\\w+)'(\\w+)\", token)\n",
        "          if match:\n",
        "              processed_tokens.append(match.group(1))\n",
        "              processed_tokens.append(\"'\" + match.group(2))\n",
        "          else:\n",
        "               # Handle cases like \"don't\"\n",
        "              match = re.match(r\"(\\w+)n't\", token)\n",
        "              if match:\n",
        "                  processed_tokens.append(match.group(1))\n",
        "                  processed_tokens.append(\"n't\")\n",
        "              else:\n",
        "                   processed_tokens.append(token) # keep token if not a recognized contraction pattern\n",
        "      else:\n",
        "          processed_tokens.append(token)\n",
        "\n",
        "  return processed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwhuR9xi5o3I",
        "outputId": "4aba4fa5-d4af-4419-f770-7c360f0147de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      [#lamadre, para, esos, usuarios, de, @TransMil...\n",
            "1      [8, años, de, un, patio, taller, del, SITP, ',...\n",
            "2      [La, @CAR_Cundi, de, manera, antidemocrática, ...\n",
            "3      [@TransMilenio, manden, buses, acaba, de, lleg...\n",
            "4      [., @Bogota, sigue, disminuyendo, el, número, ...\n",
            "                             ...                        \n",
            "995    [Por, fin, se, transformó, 😱😱😱, #AnimesDel1, 🤩...\n",
            "996    [I, 'm, at, Centro, Comercial, @ParqueLaColina...\n",
            "997    [2018,, gracias, 💙, en, Bogotá,, Colombia, htt...\n",
            "998    [Good, Morning, en, Bogotá,, Colombia, https:/...\n",
            "999    [Para, la, señora, @MariaFdaCabal, los, únicos...\n",
            "Name: text, Length: 1000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "result = data['text'].apply(tokenize)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Is_gRgkCSyd",
        "outputId": "df1e0e83-a5bb-49c6-e634-f7c17e9faf75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jajajajajajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'jajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'jajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'jajajajajajaja',\n",
              " 'Jajajajajajajajajajaja',\n",
              " 'https://t.co/dDHAAgGrvJ']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "result[950]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVhJqjXJ6g_i",
        "outputId": "b0aac730-a3dc-4bbf-9384-42403567898c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 10: ['jajaja']\n",
            "Row 168: ['jajajajajajaja']\n",
            "Row 250: ['jajajaja']\n",
            "Row 302: ['jajajaja']\n",
            "Row 471: ['jajaja']\n",
            "Row 507: ['jaja']\n",
            "Row 946: ['jajaja']\n",
            "Row 950: ['jajajajajajaja', 'jajajajajajaja', 'jajajajajajaja']\n",
            "Row 957: ['jaja']\n"
          ]
        }
      ],
      "source": [
        "#Buscar si hay un \"hahaha\" o \"jajaja\"\n",
        "def find_laughter_tokens(tokens):\n",
        "  laughter_pattern = re.compile(r\"(ha|ja)\\1+\")\n",
        "  found_laughter = []\n",
        "  for token in tokens:\n",
        "    if laughter_pattern.fullmatch(token):\n",
        "      found_laughter.append(token)\n",
        "  return found_laughter\n",
        "\n",
        "risa = result.apply(find_laughter_tokens)\n",
        "\n",
        "# Print the entries that contain laughter tokens\n",
        "for index, laughter_list in risa.items():\n",
        "  if laughter_list:\n",
        "    print(f\"Row {index}: {laughter_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4BeE2d8W7Qd"
      },
      "source": [
        "### 3.  Normalizar\n",
        "Después de la “tokenización”, aplicar normalización. Implementar una función para normalizar tokens que tienen secuencia de letras repetidas, como:\n",
        "\n",
        "*   hahahahaha -> haha\n",
        "*   cooooool -> cool\n",
        "*   !?!?!?!!!! -> !?!?!!\n",
        "*   !!!!!????? -> !!??\n",
        "\n",
        "Aplicar otras tareas de normalización, como:\n",
        "- convertir tokens a minúscula, menos los hashtags y cuentas de usuario.\n",
        "- Encontar fechas y dejar todas en un mismo formato (escoga el formato al que desea dejar la fecha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XvBFZOTO-fCF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def normalice(tokens):\n",
        "  normalized_tokens = []\n",
        "\n",
        "  #transformar a minusculas, excepto #+ y @+\n",
        "  processed_case_tokens = []\n",
        "  for token in tokens:\n",
        "    if not (token.startswith('#') or token.startswith('@')):\n",
        "      processed_case_tokens.append(token.lower())\n",
        "    else:\n",
        "      processed_case_tokens.append(token)\n",
        "\n",
        "  for token in processed_case_tokens:\n",
        "    # Buscar diferentes formatos de fechas que puedan haber\n",
        "    date_formats = [\"%Y-%m-%d\", \"%m/%d/%Y\", \"%d-%m-%Y\", \"%d/%m/%Y\"]\n",
        "    is_date = False\n",
        "    for fmt in date_formats:\n",
        "      try:\n",
        "        date_obj = datetime.strptime(token, fmt)\n",
        "        normalized_tokens.append(date_obj.strftime(\"%Y-%m-%d\")) # Formato estandar\n",
        "        is_date = True\n",
        "        break\n",
        "      except ValueError:\n",
        "        pass\n",
        "\n",
        "    if is_date:\n",
        "        continue #Seguir a otro token\n",
        "\n",
        "    # Reducir caracteres especiales, para ja y ha\n",
        "    normalized_token = re.sub(r'(ha|ja)\\1{2,}', r'\\1\\1', token)\n",
        "    normalized_token = re.sub(r'(.)\\1{2,}', r'\\1\\1', normalized_token) # Keep general single char repetition reduction\n",
        "    normalized_tokens.append(normalized_token)\n",
        "\n",
        "  return normalized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z60ukOlv_SQr",
        "outputId": "52bead72-038a-41ea-a719-8189d7dd2db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      [#lamadre, para, esos, usuarios, de, @TransMil...\n",
            "1      [8, años, de, un, patio, taller, del, sitp, ',...\n",
            "2      [la, @CAR_Cundi, de, manera, antidemocrática, ...\n",
            "3      [@TransMilenio, manden, buses, acaba, de, lleg...\n",
            "4      [., @Bogota, sigue, disminuyendo, el, número, ...\n",
            "                             ...                        \n",
            "995    [por, fin, se, transformó, 😱😱, #AnimesDel1, 🤩,...\n",
            "996    [i, 'm, at, centro, comercial, @ParqueLaColina...\n",
            "997    [2018,, gracias, 💙, en, bogotá,, colombia, htt...\n",
            "998    [good, morning, en, bogotá,, colombia, https:/...\n",
            "999    [para, la, señora, @MariaFdaCabal, los, únicos...\n",
            "Name: text, Length: 1000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "normalized_result = result.apply(normalice)\n",
        "print(normalized_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss72v_lFCex7",
        "outputId": "682ee049-f147-4035-a733-4a4ae8d66696"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'jaja',\n",
              " 'https://t.co/ddhaaggrvj']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "normalized_result[950]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTMbELJXIDb"
      },
      "source": [
        "###4. Lematizacion- Steamming: Porter's Algorithm\n",
        "- Seleccionar un documento en inglés y aplicar el algoritmo de Porter (si desea lo puede implementar). ¿Cuáles reglas aplicó?\n",
        "- Construir un lematizador y stemming para español con al menos 10 reglas. Aplicarlo al conjunto de twitter."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Algoritmo de Porter"
      ],
      "metadata": {
        "id": "UYpx9Pdx8E5k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec70ff5a",
        "outputId": "70d8a959-84f9-4527-e4d3-41c8b708d1a8"
      },
      "source": [
        "%pip install PyPDF2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecbaa6cb",
        "outputId": "05017d60-c71e-4770-d212-8f00d200d174"
      },
      "source": [
        "#Leer e importar un archivo pdf (Ej. Paper)\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page_num in range(len(reader.pages)):\n",
        "                text += reader.pages[page_num].extract_text()\n",
        "        return text\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: The file was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "pdf_text = extract_text_from_pdf('GenomeGenerative.pdf')\n",
        "print(pdf_text[50000:55000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " bioRxiv preprint (A) We used Evo 2 to generate chromosome- and genome-scale sequences using unconstrained autoregressive\n",
            "generation. We prompted the model with portions of the H. sapiens mitochondrial genome, M. genitalium\n",
            "genome, and S. cerevisiae chromosome III and generate DNA sequences with similar lengths as those of the\n",
            "native sequence. (B) We prompted Evo 2 with genomic context as well as a portion of a highly conserved pro-\n",
            "tein and generate, measuring the sequence recovery of the Evo 2 generated gene against the natural gene. (C)\n",
            "Predicted rRNA, CDS, and tRNA counts in Evo 2 generated mitochondrial sequences using MitoZ compared\n",
            "with the natural H. sapiens mitochondrial genome values. (D) Query cover versus sequence identity of gen-\n",
            "erated mitochondrial sequences against nucleotide BLAST hits in the core_nt database with expect threshold\n",
            "of 0.05. (E) Visualizations of Evo 2 generated sequences when prompted with a 3 kb sequence from the H.\n",
            "sapiensmitochondrial genome, demonstrating variation that still retains natural synteny patterns of coding\n",
            "sequences. (F) AlphaFold 3 structure predictions of multimeric complexes from an Evo 2-generated mitochon-\n",
            "drial genomes, labeled by the sequence similarity of Evo 2-generated proteins to natural proteins based on a\n",
            "BLASTp query. (G) We prompted Evo 2 with the beginning of the M. genitalium genome and generated ∼600\n",
            "kb long sequences. Genes are annotated with Prodigal and colored based on statistically significant sequence\n",
            "similarity to natural proteins (HHpred E-value < 0.001). (H) The fraction of Prodigal annotated genes with\n",
            "HHpred hits between Evo 2 40B and M. genitalium generated by Evo 1. (I) Distribution of Prodigal annotated\n",
            "genes from Evo 2 generated M. genitalium compared with the natural genome. (J) Distribution of secondary\n",
            "structure from Evo 2 generated proteins compared to natural M. genitalium. (K ) AlphaFold 3 structure pre-\n",
            "dictions of example proteins found on Evo 2-generated prokaryotic genomic sequences show high structural\n",
            "similarity to natural proteins while diversifying the sequence composition. (L) The native genome sequence\n",
            "from S. cerevisiae chromosome III and an Evo 2-generated DNA sequence of similar length, which was gener-\n",
            "atedbypromptingthemodelwitha10kbsequencefrom S. cerevisiae chromosomeIII,arevisualizedalongside\n",
            "predicted homologous yeast gene, exon, promoter, and tRNA annotations.\n",
            "performed HHpred analysis of Prodigal-predicted ORFs against the Pfam database and found that nearly 70%\n",
            "of Evo 2 40B genes contained significant Pfam hits, a marked improvement over Evo 1 131k (18%) (Figure\n",
            "5G,H). Further, quality assessment of the generated proteins using ESMFold metrics, secondary structure\n",
            "distribution, and protein sequence identity demonstrated that the generated sequences had properties consis-\n",
            "tent with natural protein distributions, suggesting successful recapitulation of native features despite the long\n",
            "generation length (Figure 5I-K).\n",
            "To assess Evo 2’s eukaryotic sequence generation capability, we prompted Evo 2 with 10.5 kb from S. cere-\n",
            "visiaechromosomeIII(∼316kbinlength)togenerate330kbofDNA.Evo2successfullygeneratedeukaryotic-\n",
            "like DNA sequences with predicted tRNAs, appropriately positioned promoters, and genes exhibiting intronic\n",
            "structure (Methods; Figures5LandS8F). Furthermore, generated proteins showed sequence and structural\n",
            "(FigureS8G-I) similarity to natural yeast genes (Figure S8I), highlighting Evo 2’s ability to generate realistic\n",
            "eukaryotic coding sequences.\n",
            "While the density of tRNA and gene features was below those found in the native yeast genome (Figures\n",
            "5LandS8G), we note that these genome sequences were produced by simple, unconstrained autoregressive\n",
            "generation. Improvements in the naturalness of generated genomes can most likely be addressed through\n",
            "optimized inference strategies or model improvements. Moreover, as demonstrated in our previous study\n",
            "(Merchantetal., 2024), genomicsequenceswithnosignificantsequencesimilaritytonaturalsequencescould\n",
            "still be semantically valid and retain function.\n",
            "Together, our results demonstrate that Evo 2 is able to generate DNA sequences that resemble organelle,\n",
            "prokaryotic, and eukaryotic genomes. These generated sequences contain both coding and noncoding ele-\n",
            "ments, with diverse yet realistic genes that maintain both structural and sequence similarity to natural se-\n",
            "quences.\n",
            "2.6. Generative epigenomics via inference-time search\n",
            "Beyondunconstrainedautoregressivegeneration,wealsosoughttoachieveguidedgenerationoflonggenomic\n",
            "sequences with Evo 2. Eukaryotic genomes regulate gene expression through a complex system of chemical\n",
            "and protein-mediated modifications referred to as the epigenome. An important component of epigenomic\n",
            "regulation involves modifying the openness or compactness of chromatin, which in turn controls which DNA\n",
            "regions can be accessed by transcriptional machinery. Chromatin accessibility is modulated by both DNA\n",
            "14. CC-BY-ND 4.0 International lic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizar las palabras con  la funcion creada anteriormente\n",
        "tokenized_pdf = tokenize(pdf_text)\n",
        "print(tokenized_pdf[10000:20000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbfGNxX21aDL",
        "outputId": "d719aba4-efd3-4a42-87ef-0261f1e16456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['large', 'models', 'spanning', 'application', 'domains', 'of', 'biology', 'and', 'natural', 'language.', 'We', 'include', 'Pythia', 'Large', '(Biderman', 'et', 'al.,', '2023),', 'OLMo', '2', 'Large', '(Team', 'OLMo', 'et', 'al.,', '2024),', 'Evo', '1,', 'Falcon', '1', '180B', 'Almazrouei', 'et', 'al.', '(2023),', 'StarCoder', '2', '(Lozhkov', 'et', 'al.,', '2024),', 'DeepSeek', 'V3', '(Liu', 'et', 'al.,', '2024),', 'Llama', '3.1', 'Large', '(Dubey', 'et', 'al.,', '2024),', 'ESM', '3', 'Large', '(Hayes', 'et', 'al.,', '2025)', 'and', 'xTrimo', '(Chen', 'et', 'al.,', '2024).', 'Model', 'Model', 'Size', 'Tokens', 'FLOPS', 'est.', 'Fully', 'open:', 'data,', 'infrastructure,', 'weights', 'Evo', '2', '40B', '40.3B', '9.3T', '2.25×1024', 'Pythia', 'Large', '12B', '300B', '2.16×1022', 'OLMo', '2', 'Large', '13B', '5.6T', '4.37×1023', 'Open', 'data,', 'weights', 'Evo', '1', '7B', '300B', '1.26×1022', 'Falcon', '180B', '180B', '3.5T', '3.78×1024', 'StarCoder', '2', '15B', '15B', '4.3T', '3.87×1023', 'Open', 'weights', 'only', 'DeepSeek', 'V3', '37B', '(671B', 'total)', '14.8T', '3.28×1024', 'Llama', '3.1', 'Large', '405B', '15T', '3.64×1025', 'Closed', 'ESM', '3', 'Large', '98B', '771B', '1.07×1024', 'xTrimo', 'Large', '100B', '1T', '6.00×1023', 'Table', '1|Comparison', 'of', 'training', 'FLOPS', 'across', 'flagship', 'language', 'and', 'biology', 'models,', 'showing', 'Evo', '2', 'as', 'the', 'largest', 'fully', 'open', 'model.', 'FLOPS', 'are', 'estimated', 'without', 'accounting', 'for', 'mixed-precision', 'or', 'pretraining', 'context', 'length.', '4.1.1.', 'Model', 'architecture', 'Evo', '2', 'uses', 'StripedHyena', '2', '(Ku', 'et', 'al.,', '2025),', 'the', 'first', 'multi-hybrid', 'architecture', 'based', 'on', 'input-dependent', 'convolutions', '(Poli', 'et', 'al.,', '2023;Nguyen', 'et', 'al.,', '2024b).', 'Multi-hybrids', 'combine', 'various', 'different', 'operators', 'to', 'balance', 'model', 'quality', 'with', 'training', 'and', 'inference', 'efficiency,', 'in', 'line', 'with', 'findings', 'of', 'Poli', 'et', 'al.', '(2024)', 'and', 'Thomas', 'et', 'al.', '(2024).FigureS1provides', 'a', 'schematic', 'of', 'each', 'new', 'convolutional', 'operator', 'in', 'the', 'architecture.', 'Self-attention', 'layers', 'use', 'rotary', 'positional', 'embeddings', '(Su', 'et', 'al.,', '2024).', 'Model', 'size', 'information', 'and', 'hyperparameters', 'used', 'for', 'Evo', '2', 'models', 'are', 'shown', 'in', 'Table2.', 'Each', 'Evo', '2', 'model', 'uses', 'a', 'pattern', 'of', 'Hyena-SE,', 'Hyena-MR', 'andHyena-LI,', 'and', 'attention,', 'with', 'the', 'number', 'of', 'repetitions', 'scaling', 'with', 'model', 'size.', 'Hyena-SE', 'uses', 'inner', 'filters', 'of', 'length', '7,', 'Hyena-MR', 'length', '128.', 'GELU', 'activations', 'are', 'only', 'used', 'for', 'the', 'first', 'layer,', 'followed', 'by', 'no', 'activations.', '19.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'Evo', '2', '40B', 'Evo', '2', '7B', 'Evo', '2', '1B', 'base', 'Parameters', '40.3B', '6.5B', '1.1B', 'Total', 'Layers', '50', '32', '25', 'Hidden', 'Size', '8,192', '4,096', '1,920', 'FFN', 'Size', '22,528', '11,264', '5,120', 'Num', 'Heads', '64', '32', '15', 'Total', 'Tokens', '9.3T', '2.4T', '1T', 'Table', '2|Model', 'architecture', 'configurations', 'for', 'Evo', '2', 'models', '4.1.2.', 'Loss', 'function', 'Evo', '2', 'is', 'trained', 'with', 'a', 'reweighted', 'cross', 'entropy', 'loss,', 'which', 'weighs', 'the', 'loss', 'contribution', 'of', 'repetitive', 'portions', 'of', 'DNA', 'by', '0.1.', 'This', 'affects', 'the', 'genomic', 'window', 'and', 'whole', 'genome', 'portions', 'of', 'the', 'data', 'which', 'contain', 'these', 'annotations.', 'This', 'loss', 'has', 'been', 'found', 'in', 'other', 'DNA', 'models', 'to', 'improve', 'performance', 'on', 'downstream', 'tasks', 'and', 'better', 'calibrate', 'likelihoods', 'between', 'repetitive', 'and', 'nonrepetitive', 'DNA', '(Benegas', 'et', 'al.,', '2025),', 'which', 'we', 'found', 'to', 'be', 'true', 'for', 'downstream', 'tasks', 'in', 'a', 'controlled', 'comparison', '(Appendix', 'B.1).', 'The', 'loss', 'is', 'ℓwCE=1', '𝑍', '∑', '︁', '𝑡𝑤𝑡', 'ℓCE(', '𝑡', ')', 'with', 'weighting', '𝑤𝑡', '=(', '0.1if', 'position', '𝑡', 'is', 'in', 'repetitive', 'region', '1.0otherwise', '𝑍', '=0.1', '𝑁', 'repeat+', '𝑁', 'non_repeat', 'where', '𝑤𝑡', 'istheweightappliedtoeachposition,', '𝑁', 'repeatsrepresentsthenumberofpositionsinrepetitiveregions', 'within', 'a', 'batch', 'and', '𝑁', 'non_repeat', 'is', 'the', 'number', 'of', 'non', 'repetitive', 'regions,', 'and', '𝑍', 'is', 'the', 'normalization', 'factor', 'that', 'ensures', 'consistent', 'loss', 'scaling', 'regardless', 'of', 'the', 'proportion', 'of', 'repetitive', 'regions.', 'For', 'any', 'base', 'pair,', 'the', 'model', 'is', 'always', 'tasked', 'with', 'predicting', 'the', 'uppercase', 'character.', 'For', 'the', 'first', '3T', 'tokens', 'of', 'pretraining,', 'lowercase', 'tokens', 'are', 'input', 'to', 'the', 'model', 'to', 'add', 'information', 'on', 'which', 'portions', 'of', 'DNA', 'are', 'repetitive.', 'This', 'was', 'done', 'to', 'further', 'help', 'learn', 'different', 'representations', 'for', 'interspersed', 'repeats,', 'which', 'are', 'very', 'common', 'in', 'many', 'eukaryotic', 'genomes.', 'For', 'additional', 'pretraining', 'and', 'for', 'all', 'midtraining,', 'all', 'inputs', 'to', 'the', 'model', 'are', 'uppercase.', 'Loss', 'is', 'masked', 'on', 'special', 'tokens', 'used', 'to', 'condition', 'the', 'model', 'that', 'we', 'do', 'not', 'want', 'to', 'generate,', 'including', 'the', 'stitch', 'tokens', '‘@’', 'and', '‘#’', ',', 'as', 'well', 'as', 'the', 'multi-token', 'phylogenetic', 'tags', 'used', 'during', 'midtraining.', '4.1.3.', 'Pretraining', 'infrastructure', 'Evo', '2', 'was', 'trained', 'on', 'Savanna', '(see', 'Section', '6),', 'custom', 'training', 'infrastructure', 'built', 'with', 'components', 'from', 'DeepSpeed,', 'GPT-NeoX', '(Andonian', 'et', 'al.,', '2023),', 'and', 'Transformer', 'Engine.', 'Our', 'stack', 'supports', 'efficient', 'pre-', 'training', 'of', 'multi-hybrid', 'models', 'and', 'new', 'context', 'parallel', 'algorithms.', 'We', 'train', 'our', 'largest', 'models', 'with', 'mixed', 'precision,usinga3Dmeshofdata,tensor,andcontextparallelism,combinedwithZeRO-3(Rajbhandarietal.,', '2020).', 'During', 'training,', 'we', 'use', 'Transformer', 'Engine’s', 'FP8', 'implementation', 'for', 'linear', 'layers', 'and', 'RMSNorms.', '4.1.4.', 'Pretraining', 'phase', 'Table3provides', 'information', 'on', 'our', 'pretraining', 'configuration.', 'We', 'refer', 'to', 'the', 'models', 'after', 'pretraining', 'but', 'before', 'context', 'extension', 'as', 'Evo', '2', '40B', 'and', '7B', 'base.', '20.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'Evo', '2', '40B', 'base', 'Evo', '2', '7B', 'base', 'Evo', '2', '1B', 'base', 'Learning', 'Rate', '2.0e-4', '3.0e-4', '3.0e-4', 'Training', 'Batch', '16.8M', '4.2M', '2.1M', 'Total', 'Iterations', '516K', '500K', '490K', 'Pretraining', 'Tokens', '8.7T', '2.1T', '1T', 'Sequence', 'length', '1024', '(6.6T),', '8192', '(1.1T)', '8192', '8192', 'Table3|PretraininghyperparametersforEvo2models.', 'EachmodelusestheAdamWoptimizerwith', '𝛽', '1=0.9,', '𝛽', '2=0.95,', 'and', 'cosine', 'learning', 'rate', 'decay.', '4.1.5.', 'Midtraining', 'phase:', 'Context', 'extension', 'We', 'follow', 'a', 'multi-stage', 'midtraining', 'procedure,', 'gradually', 'extending', 'the', 'context', 'length', 'while', 'keeping', 'the', 'same', 'batch', 'size', 'as', 'pretraining,', 'adjusting', 'model', 'parallelism', 'accordingly.', 'Midtraining', 'was', 'performed', 'on', 'an', 'adjusted', 'data', 'composition,', 'including', 'more', 'whole', 'genomes', 'and', 'with', 'longer', 'average', 'sequence', 'length', '(Figure', '1,', 'Appendix', 'S5).', 'We', 'explore', 'two', 'different', 'rotary', 'embedding-based', 'methods', 'to', 'adapt', 'to', 'longer', 'sequences:', 'positional', 'inter-', 'polation', 'by', 'down', 'scaling', 'the', 'positional', 'index', 'of', 'tokens', '(Chen', 'et', 'al.,', '2023)', 'and', 'increasing', 'the', 'base', 'frequency', 'of', 'the', 'RoPE', 'embedding', '(Xiong', 'et', 'al.,', '2023).', 'We', 'decide', 'on', 'a', 'combined', 'approach', 'using', 'both', 'together,', 'with', 'a', '10×increase', 'to', 'the', 'base', 'frequency', 'for', 'every', 'doubling', 'of', 'the', 'context', 'length.', 'Table4provides', 'information', 'on', 'our', 'midtraining', 'protocol.', 'After', 'extension', 'stages,', 'model', 'performance', 'was', 'evaluated', 'using', 'loss,', 'performance', 'on', 'short', 'sequence', 'DMS', 'tasks,', 'and', 'performance', 'on', 'our', 'long', 'context', 'needle-in-a-haystack', 'evaluation', 'to', 'evaluate', 'effectiveness', 'of', 'the', 'extension.', 'We', 'didnot', 'find', 'significantdifferences', 'betweendifferent', 'extension', 'protocols.', 'Basedon', 'the', 'success-', 'ful', 'context', 'extension', 'results', 'for', 'the', '7B,', 'we', 'reduced', 'the', 'number', 'of', 'stages', 'and', 'increase', 'the', 'number', 'of', 'tokens', 'for', 'the', '40B,', 'seeing', '600B', 'tokens', 'during', 'midtraining.', 'Context', 'Length', 'Base', 'Frequency', 'Scale', 'Factor', 'Evo', '2', '7B', 'Evo', '2', '40B', 'Training', 'Tokens', '32.8K', '1.0×1064', '50B', '-', '65.5K', '1.0×1078', '50B', '-', '131.1K', '1.0×10816', '50B', '200B', '262.1K', '1.0×10932', '50B', '200B', '524.3K', '1.0×101064', '50B', '-', '1048.6K', '1.0×1011128', '50B', '200B', '300B', '600B', 'Table', '4|Context', 'extension', 'protocol', 'and', 'number', 'of', 'tokens', 'for', 'Evo', '2', '7B', 'and', '40B', '4.1.6.', 'Midtraining', 'phase:', 'Needle-in-a-haystack', 'evaluation', 'WedevelopedanovelsyntheticevaluationtoassesstheabilityofDNAlanguagemodelstoidentifyandutilizea', 'specificsequencepatterninitscontexttomakepredictionsonarepeatedsequencewiththesamepattern.', 'This', '“needle-in-haystack”', 'evaluation', 'quantifies', 'a', 'model’s', 'capacity', 'to', 'retrieve', 'sequence', 'patterns', 'within', 'different', 'context', 'lengths.', 'For', 'each', 'evaluation,', 'we', 'generated', 'a', 'random', 'DNA', 'sequence', 'of', '100', 'base', 'pairs', '(bp)', 'to', 'serve', 'as', 'the', '“needle”', 'sequence.', 'A', 'background', 'sequence', '(“haystack”)', 'was', 'constructed', 'by', 'sampling', 'DNA', 'base', 'pairs', 'uniformly', 'at', 'random', 'at', 'varying', 'lengths', 'following', 'powers', 'of', 'two,', 'ranging', 'from', '512', 'bp', 'to', '1,048,576', 'bp.', 'The', 'needle', 'sequence', 'was', 'systematically', 'inserted', 'at', 'different', 'relative', 'positions', 'within', 'each', 'haystack,', 'specifically', 'at', 'depths', 'corresponding', 'to', '10%', 'through', '90%,', 'at', 'intervals', 'of', '10%,', 'of', 'the', 'total', 'haystack', 'length.', 'A', '“query”', 'sequence,', 'which', 'is', 'an', 'exact', 'duplicate', 'of', 'the', 'needle', 'sequence,', 'was', 'then', 'placed', 'at', 'the', 'suffix', 'of', 'the', 'haystack', 'sequence.', 'The', 'evaluation', 'methodology', 'employs', 'a', 'modification', 'of', 'the', '“categorical', 'Jacobian”', 'analysis,', 'as', 'originally', '21.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'proposed', 'by', 'Zhang', 'et', 'al.', '(2024),', 'to', 'measure', 'the', 'model’s', 'use', 'of', 'the', 'needle', 'sequence', 'to', 'predict', 'the', 'query', 'sequence.', 'At', 'a', 'high-level,', 'we', 'mutate', 'the', 'needle', 'and', 'measure', 'the', 'effects', 'on', 'model', 'predictions', 'for', 'the', 'query', 'as', 'a', 'way', 'to', 'assess', 'retrieval.', 'More', 'formally,', 'let', 'Cdenote', 'the', 'categorical', 'Jacobian', 'matrix', 'using', 'the', 'notation', 'from', 'Nguyen', 'et', 'al.', '(2024a),', 'where', 'the', 'entry', 'C[', '𝑖', ',', '𝑗', ']indicates', 'the', 'Euclidean', 'magnitude', 'of', 'the', 'difference', 'in', 'logits', 'at', 'position', '𝑗', 'when', 'mutating', 'position', '𝑖', 'to', 'all', 'tokens', 'in', 'the', 'vocabulary.', 'We', 'compute', 'a', 'retrieval', 'score', '𝑟', '=1', '𝑁', 'needle∑', '︁', '𝑖', '∈[0,', '𝑁', 'needle−1]C[', '𝑎', 'needle+', '𝑖', ',', '𝑎', 'query+', '𝑖', ']', 'where', '𝑁', 'needle', '=100is', 'the', 'length', 'of', 'the', 'needle', '(and', 'of', 'the', 'query)', 'sequence,', '𝑎', 'needleis', 'the', 'starting', 'position', 'of', 'the', 'needle', 'and', '𝑎', 'queryis', 'the', 'starting', 'position', 'of', 'the', 'query.', 'High', 'values', 'of', '𝑟', 'indicate', 'greater', 'retrieval', 'strength.', 'We', 'use', 'a', 'threshold', 'of', '𝑟', '≥0.8to', 'determine', 'successful', 'retrieval,', 'which', 'was', 'obtained', 'by', 'manually', 'inspecting', 'categorical', 'Jacobian', 'matrices', 'of', 'synthetic', 'sequences', 'containing', 'repeated', 'motifs.', 'We', 'computed', 'the', 'retrieval', 'score', 'for', 'various', 'haystack', 'lengths', 'and', 'when', 'inserting', 'the', 'needle', 'at', 'various', 'depths', 'into', 'the', 'haystack.', '4.1.7.', 'Inference', 'infrastructure', 'Evo', '2', 'inference', 'runs', 'on', 'Vortex', '(see', 'Section6).', 'Vortex', 'contains', 'infrastructure', 'and', 'efficient', 'implementation', 'for', 'autoregressive', 'generation', 'with', 'StripedHyena', '2.', 'For', 'the', 'new', 'convolution', 'operators', 'with', 'finite', 'inner', 'filters,', 'we', 'adopt', 'a', 'caching', 'strategy', 'similar', 'to', 'KV', 'caching', 'in', 'self-attention.', 'For', 'long', 'filters,', 'we', 'switch', 'to', 'a', 'recurrent', 'form.', 'All', 'convolution', 'operators', 'in', 'the', 'architecture', 'can', 'generate', 'autoregressively', 'with', 'a', 'constant', 'memory', 'footprint.', '4.2.', 'OpenGenome2', 'training', 'data', 'WesignificantlyexpandedupontheOpenGenomepretrainingdataset,usedtotrainEvo1,tocreateOpenGenome2,', 'increasing', 'the', 'total', 'number', 'of', 'nucleotides', 'from', '300', 'billion', 'to', '8.84', 'trillion.', 'This', 'included', 'a', '33%', 'expansion', 'of', 'representative', 'prokaryotic', 'genomes', 'from', '85,205', 'to', '113,379', '(357', 'billion', 'nucleotides),', 'a', 'total', 'of', '6.98', 'tril-', 'lion', 'nucleotides', 'from', 'eukaryotic', 'genomes,', '854', 'billion', 'nucleotides', 'of', 'non-redundant', 'metagenomic', 'sequencing', 'data,', '2.82', 'billion', 'nucleotides', 'of', 'organelle', 'genomes,', 'and', '602', 'billion', 'nucleotides', 'of', 'subsets', 'of', 'eukaryotic', 'se-', 'quence', 'data', 'to', 'focus', 'on', 'likely', 'functional', 'regions', 'of', 'the', 'genomes', 'by', 'focusing', 'on', 'different', 'windows', 'around', 'coding', 'genes.', 'We', 'introduced', 'these', 'data', 'augmentations', 'to', 'prioritize', 'genes', 'and', 'regions', 'around', 'genes', 'to', 'im-', 'prove', 'performance', 'on', 'downstream', 'tasks', '(Appendix', 'B.2).', '4.2.1.', 'Data', 'curation', 'Reused', 'datasets.', 'Our', 'previously', 'published', 'OpenGenome', 'dataset', 'was', 'used', 'in', 'its', 'entirety', 'as', 'part', 'of', 'the', 'trainingdataforthisstudy(Nguyenetal.,', '2024a).', 'Thisincludedrepresentativeprokaryoticgenomesavailable', 'through', 'GTDB', 'release', 'v214.1,', 'and', 'curated', 'phage', 'and', 'plasmid', 'sequences', 'retrieved', 'through', 'IMG/VR', 'and', 'IMG/PR.', 'As', 'previously', 'described,', 'the', 'OpenGenome', 'dataset', 'was', 'curated', 'to', 'exclude', 'genomic', 'sequences', 'of', 'viruses', 'which', 'infect', 'eukaryotic', 'hosts.', 'Updated', 'prokaryotic', 'genomes.', 'New', 'prokaryotic', 'reference', 'genomes', 'made', 'available', 'through', 'the', 'GTDB', 're-', 'lease', '220.0', '(Parks', 'et', 'al.,', '2022)', 'update', 'were', 'added', 'to', 'the', 'training', 'data', 'for', 'this', 'study.', 'New', 'genomes', 'were', 'identifiedbyselectingallspecies’referencegenomesthathadnopreviouslypublished(release214.1)genomes', 'within', 'their', 'species', 'cluster,', 'resulting', 'in', '28,174', 'additional', 'prokaryotic', 'genomes.', 'Eukaryotic', 'reference', 'genomes.', 'All', 'available', 'eukaryotic', 'reference', 'genomes', 'were', 'downloaded', 'from', 'NCBI', 'on', 'May', '31,', '2024,', 'excluding', 'atypical', 'genomes,', 'metagenome-assembled', 'genomes,', 'and', 'genomes', 'from', 'large', 'multi-isolate', 'projects.', 'This', 'resulted', 'in', '16,704', 'genomes', 'including', 'an', 'estimated', '10.7', 'trillion', 'nucleotides.', 'Only', 'contigs', 'that', 'were', 'annotated', 'as', '‘Primary', 'Assembly’,', '‘non-nuclear’,', 'or', '‘aGasCar1.hap1’', '(an', 'aberrant', 'annotation', 'that', 'applied', 'only', 'to', 'GCA_027917425.1)', 'were', 'retained.', 'Mash', 'sketch', 'was', 'run', 'on', 'each', 'individual', 'genome', 'with', 'the', 'flag', '“-s', '10000”', 'and', 'the', 'mash', 'distance', 'was', 'calculated', 'between', 'all', 'genomes', 'as', 'an', 'estimate', 'for', 'their', 'pairwise', '1-ANI', '(average', 'nucleotide', 'identity)', '(Ondov', 'et', 'al.,', '2016).', 'All', 'genomes', 'with', 'a', 'mash', 'distance', '<', '0.01', 'were', 'joined', 'with', 'edges', 'in', 'a', 'graph', '(Csárdi', 'et', 'al.,', '2024),', 'and', 'clusters', 'were', 'identified', 'by', 'finding', 'connected', '22.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'components.', 'One', 'representative', 'genome', 'per', 'cluster', 'was', 'chosen,', 'prioritizing', 'genomes', 'with', 'a', 'higher', 'assembly', 'level', 'and', 'genomes', 'with', 'longer', 'total', 'sequence', 'length.', 'This', 'clustering', 'resulted', 'in', '15,148', 'candidate', 'genomes.', 'Genomes', 'were', 'further', 'filtered', 'by', 'removing', 'ambiguous', 'nucleotides', 'at', 'the', 'termini', 'of', 'each', 'contig,', 'by', 'removing', 'regions', 'annotated', 'as', '“centromere”', 'in', 'an', 'available', 'GFF', 'file,', 'and', 'by', 'removing', 'contigs', 'that', 'were', 'less', 'than', '10', 'kb', 'in', 'total', 'length.', 'Finally,', 'contigs', 'that', 'were', 'composed', 'of', 'more', 'than', '5%', 'ambiguous', 'nucleotides', 'were', 'removed.', 'This', 'final', 'filtered', 'set', 'included', '15,032', 'genomes', 'and', '6.98', 'trillion', 'nucleotides.', 'Metagenomes.', 'A', 'previously', 'described', 'metagenomics', 'dataset', '(Durrant', 'et', 'al.,', '2024)', 'was', 'further', 'curated', 'as', 'part', 'of', 'the', 'training', 'data.', 'This', 'included', '41,253', 'metagenomes', 'and', 'metagenome-assembled', 'genomes', 'from', 'NCBI,JGIIMG(Chenetal.,', '2021),MGnify(Mitchelletal.,', '2020),MG-RAST(Meyeretal.,', '2008),TaraOceans', 'samples', '(Sunagawa', 'et', 'al.,', '2015),', 'and', 'Youngblut', 'et', 'al.', 'animal', 'gut', 'metagenomes', '(Youngblut', 'et', 'al.,', '2020).', 'All', 'contigs', 'were', 'split', 'at', 'consecutive', 'stretches', 'of', 'ambiguous', 'nucleotides', 'of', 'length', '5', 'bp', 'or', 'longer,', 'the', 'split', 'contigs', 'were', 'filtered', 'by', 'a', 'minimum', 'sequence', 'length', 'of', '1', 'kb,', 'and', 'only', 'contigs', 'with', 'at', 'least', 'one', 'open', 'reading', 'frame', 'as', 'predicted', 'by', 'Prodigal', '(Hyatt', 'et', 'al.,', '2010)', 'were', 'kept.', 'Contig-encoded', 'proteins', 'were', 'previously', 'clustered', 'at', '90%identityusingMMseqs(Durrantetal.,', '2024;SteineggerandSöding,', '2017).', 'Tofurtherremoveredundant', 'sequences,', 'contigs', 'were', 'sorted', 'by', 'descending', 'length,', 'and', 'each', 'contig', 'was', 'only', 'retained', 'if', 'at', 'least', '90%', 'of', 'its', 'respective', 'protein', 'clusters', 'were', 'not', 'already', 'in', 'the', 'sequence', 'collection', '(determined', 'using', 'a', 'bloom', 'filter', 'from', 'the', 'pybloom', 'package', 'with', 'a', 'capacity', 'of', '1614960255', 'and', 'an', 'error', 'rate', 'of', '1e-6).', 'Eukaryoticorganellegenomes.', '33,457organellegenomeswereidentifiedanddownloadedusingthe“NCBI', 'Organelle”webresource.', 'Ambiguousnucleotidesattheterminalendsoftheorganellegenomesequenceswere', 'removed.', 'Sequencesthathadover25ambiguousnucleotideswereremoved.', 'Thisresultedin32,240organelle', 'genomes', 'that', 'were', 'used', 'for', 'training,', 'including', '17,613', 'mitochondria,', '12,856', 'chloroplasts,', '1,751', 'plastids,', '18', 'apicoplasts,', '1', 'cyanelle,', 'and', '1', 'kinetoplast.', 'mRNAandncRNAtranscripts.', 'TranscriptswereextractedusingGTFfilesthatwereavailablethroughNCBI', 'for', '4,390', 'reference', 'genomes.', 'All', 'transcripts', 'were', 'extracted', 'using', 'these', 'coordinates,', 'and', 'the', 'longest', 'repre-', 'sentative', 'transcript', 'per', 'gene', 'was', 'selected', 'to', 'limit', 'sequence', 'redundancy.', 'Transcripts', 'from', 'each', 'representative', 'genomewerethenfilteredtobeatleast64nucleotidesinlengthandlessthan100kbinlength,andtranscripts', 'that', 'had', 'consecutive', 'stretches', 'of', 'ambiguous', 'nucleotides', 'that', 'were', '5', 'bp', 'or', 'longer', 'were', 'removed.', 'Transcripts', 'were', 'clustered', 'with', 'mmseqs', 'at', '90%', 'identity', 'for', 'each', 'genome', 'to', 'reduce', 'redundancy.', 'Transcripts', 'were', 'then', 'split', 'into', '“mRNA”', 'and', 'ncRNA', '(not-mRNA)', 'by', 'using', 'the', 'gbkey', 'field', 'of', 'the', 'GTF', 'file.', 'All', 'mRNA', 'and', 'ncRNA', 'transcripts', 'across', 'all', 'species', 'were', 'then', 'grouped', 'together,', 'and', 'separately', 'clustered', 'again', 'using', 'mmseqs', 'at', '90%', 'identity.', 'Noncoding', 'RNAs.', 'ncRNA', 'sequences', 'were', 'obtained', 'from', 'Ensembl', '(release', '112),', 'Rfam,', 'and', 'RNAcentral.', 'For', 'Ensembl,', 'we', 'used', 'sequences', 'explicitly', 'annotated', 'as', '“ncrna”', 'across', '338', 'reference', 'genomes.', 'For', 'Rfam', 'and', 'RNAcentral,', 'we', 'downloaded', 'all', 'available', 'sequences', 'in', 'each', 'database.', 'All', 'ncRNA', 'sequences', 'were', 'then', 'combined', 'into', 'a', 'single', 'FASTA', 'file', 'and', 'then', 'clustered', 'with', 'mmseqs', 'easy-linclust', 'with', 'parameters', '–min-seq-id', '0.9,', '-c', '0.8,', 'and', '–cov-mode', '0', 'to', 'produce', 'the', 'final', 'set', 'of', 'sequences', 'for', 'training.', 'Eukaryoticpromoters(EPDnew).', 'Sequencesfrom15organismsconsistingof600bprepresentingpositions', '−499', 'to', '100', 'relative', 'to', 'the', 'transcription', 'start', 'sites,', 'which', 'correspond', 'to', 'experimentally', 'validated', 'promoter', 'sequences,', 'were', 'obtained', 'from', 'the', 'EPDnew', 'database.', 'These', 'sequences', 'were', 'then', 'clustered', 'with', 'mmseqs', 'easy-linclust', 'with', 'parameters', '–min-seq-id', '0.9,', '-c', '0.8,', 'and', '–cov-mode', '0', 'to', 'produce', 'the', 'final', 'set', 'of', 'sequences', 'for', 'training.', '4.2.2.', 'Data', 'processing', 'and', 'tokenization', 'Datasets', 'were', 'preprocessed', 'differently', 'for', 'pretraining', 'and', 'midtraining', 'to', 'reflect', 'the', 'different', 'lengths', 'of', 'train-', 'ing.', 'We', 'augment', 'the', 'data', 'in', 'order', 'to', 'focus', 'model', 'pretraining', 'on', 'more', 'conserved,', 'information', 'dense', 'regions', 'around', 'genes,', 'inspired', 'by', 'previous', 'approaches', '(Benegas', 'et', 'al.,', '2023).', 'To', 'enable', 'data', 'augmentations', 'and', 'stitching', 'of', 'multiple', 'contigs', 'together,', 'we', 'introduce', 'two', 'special', 'tokens.', 'The', '‘#’', 'token', 'is', 'used', 'to', 'join', 'sequences', '23.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'from', 'the', 'same', 'species', 'with', 'uncertain', 'distance', 'to', 'each', 'other,', 'while', 'the', '‘@’', 'token', 'is', 'used', 'for', 'sequences', 'that', 'are', 'from', 'the', 'same', 'contig/strand', 'and', 'are', 'near', 'each', 'other.', 'We', 'perform', 'a', 'data', 'ablation', 'to', 'test', 'the', 'effectiveness', 'of', 'our', 'data', 'composition', 'compared', 'to', 'one', 'with', 'fewer', 'augmentations', '(Appendix', 'B.2).', 'For', 'pretraining,', 'we', 'perform', 'the', 'following', 'additional', 'filtering,', 'processing,', 'and', 'augmentation', 'strategies.', 'We', 'use', 'both', 'ncRNA', 'and', 'mRNA', 'transcript', 'annotations', 'to', 'generate', 'the', 'augmented', 'transcripts', 'and', 'gene', 'windows', 'data', 'portions.', 'GTDB', 'and', 'IMG/PR.', 'We', 'reverse', 'complement', '50%', 'of', 'the', 'sequences.', 'A', 'random', 'set', 'of', '100', 'sequences', 'was', 'used', 'for', 'validation.', 'Transcripts.', 'Sequences', 'with', '3', 'continuous', '‘N’', 'nucleotides', 'were', 'removed,', 'and', 'all', 'uracil', 'is', 'replaced', 'with', 'thymine.', 'We', 'reverse', 'complement', '50%', 'of', 'the', 'sequences.', 'A', 'random', 'set', 'of', '1000', 'sequences', 'is', 'held', 'out', 'for', 'validation.', 'Augmented', 'transcripts:', 'Eukaryote', 'promoter,', 'exon,', 'and', 'splice', 'overhangs', 'As', 'a', 'separate', 'data', 'aug-', 'mentation,', 'the', 'same', 'set', 'of', 'clustered', 'mRNA', 'and', 'ncRNA', 'transcripts', '(see', 'Section4.2.1)', 'were', 'modified', 'to', 'include', 'an', 'additional', '1,024', 'bp', 'of', 'starting', 'sequence', 'and', 'an', 'additional', '32', 'bp', 'around', 'each', 'exon', 'for', 'additional', 'splice', 'site', 'information.', 'These', '“stitched”', 'transcript', 'sequences', 'were', 'then', 'combined', 'together', 'for', 'each', 'transcript', 'using', 'a', 'special', '“@”', 'token.', 'Eukaryotic', 'genic', 'regions.', 'We', 'use', 'windows', 'around', 'annotated', 'genes', 'to', 'enrich', 'functional', 'coding', 'and', 'cis', 'regulatory', 'elements', 'in', 'the', 'training', 'data.', 'Using', 'the', 'same', 'GTF', 'gene', 'coordinates', 'previously', 'retrieved', 'from', 'NCBI', '(see', 'Section4.2.1),', 'we', 'created', 'an', 'augmented', 'collection', 'of', 'eukaryotic', 'sequences', 'that', 'were', 'enrichedaroundcodingandnoncodingexons.', 'Alltranscriptsthatwereretainedafterallfilteringstepsof', 'themRNAandncRNAtranscriptcurationprocess(see', 'Section4.2.1)wereidentified,with5000bpfrom', 'both', 'sides', 'of', 'each', 'exon', 'coordinate.', 'These', 'coordinates', 'were', 'then', 'merged', 'using', 'bedtools', '(Quinlan', 'and', 'Hall,2010)', 'in', 'a', 'strand-agnostic', 'manner,', 'and', 'contiguous', 'stretches', 'of', 'sequence', 'were', 'then', 'extracted', 'from', 'each', 'respective', 'genome', 'sequence', 'file.', 'All', 'extracted', 'sequences', 'were', 'then', 'split', 'at', 'consecutive', 'stretches', 'of', 'ambiguous', 'nucleotides', 'of', 'length', '5', 'bp', 'or', 'longer,', 'and', 'the', 'remaining', 'sequences', 'were', 'filtered', 'to', 'be', 'at', 'least', '1,000', 'nucleotides', 'in', 'length.', 'The', '‘@’', 'token', 'is', 'used', 'to', 'join', 'sequences', 'from', 'the', 'same', 'contig.', '50%', 'of', 'entire', 'joined', 'sequences', 'are', 'reverse', 'complemented.', 'For', 'midtraining,', 'we', 'increased', 'the', 'effective', 'length', 'of', 'sequences', 'to', 'take', 'advantage', 'of', 'the', 'model’s', 'extended', 'context', 'window.', 'We', 'achieved', 'this', 'by', 'stitching', 'together', 'sequences', 'from', 'the', 'same', 'accession', 'with', 'different', 'strategies', 'for', 'each', 'dataset,', 'leading', 'to', 'effective', 'sequence', 'lengths', 'of', 'millions', 'of', 'base', 'pairs', 'for', 'prokaryotic', 'and', 'eukaryotic', 'genomes', 'so', 'that', 'the', 'model', 'sees', 'relevant', 'sequence', 'in', 'its', 'entire', 'window', 'during', 'training.', 'GTDBSequences', 'from', 'the', 'same', 'organism', 'are', 'joined', 'together', 'with', 'a', 'special', '‘#’', 'token', 'at', 'the', 'gaps.', 'This', 'increases', 'the', 'median', 'sequence', 'length', 'from', '12', 'kb', 'to', '2', 'million', 'base', 'pairs.', 'Phylogenetic', 'tags', 'are', 'added', 'every', '131', 'kb', 'to', 'help', 'condition', 'the', 'model.', 'IMG/VR', 'Phylogenetic', 'tags', 'are', 'added', 'at', 'the', 'beginning', 'of', 'every', 'IMG/VR', 'sequence', 'Eukaryotic', 'genomes', 'Sequences', 'from', 'the', 'same', 'organism', 'are', 'joined', 'together.', '‘@’', 'is', 'used', 'for', 'sequences', 'from', 'the', 'same', 'contig,', 'while', 'the', '‘#’', 'is', 'used', 'to', 'join', 'sequences', 'from', 'different', 'contigs.', 'This', 'increases', 'the', 'median', 'sequence', 'length', 'from', '15', 'kb', 'to', 'millions.', 'Transcripts,', 'augmented', 'transcripts,', 'genomic', 'windows,', 'and', 'IMGPR', 'remain', 'the', 'same', 'as', 'for', 'the', 'pretraining', 'phase.', 'Phylogenetic', 'tags', 'are', 'included', 'help', 'condition', 'the', 'model', 'during', 'midtraining,', 'and', 'loss', 'is', 'ignored', 'for', 'these', 'tokens.', 'Phylogenetic', 'tags', 'are', 'formatted', 'Greengenes-style', 'lineage', 'strings', 'which', 'concatenate', 'all', 'taxa', 'starting', 'domain', 'to', 'species,', 'with', 'all', 'uppercasing', 'separated', 'by', 'semicolons.', '’|’', 'tokens', 'are', 'added', 'at', 'the', 'start', 'and', 'end,', 'similar', 'to', 'in', 'Evo', '1', '(Nguyen', 'et', 'al.,', '2024a).', 'For', 'example,', 'the', 'tag', 'for', 'E.', 'coliwould', 'be:', '|D__BACTERIA;P__PSEUDOMONADOTA;C__GAMMAPROTEOBACTERIA;', 'O__ENTEROBACTERALES;F__ENTEROBACTERIACEAE;G__ESCHERICHIA;', 'S__ESCHERICHIA|', '24.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', '4.2.3.', 'UMAP', 'visualization', 'of', 'whole', 'genomes', 'WecreatedaUMAPvisualizationofallprokaryoticandeukaryoticrepresentativegenomesusedinthetraining', 'data', 'as', 'an', 'illustrative', 'representation', 'of', 'their', 'abundance', 'and', 'diversity.', 'K-mer', 'frequencies', 'were', 'calculated', 'for', 'allprokaryoticandeukaryoticgenomesusingjellyfish(MarçaisandKingsford,2011)andkvalues1through6.', 'These', 'were', 'combined', 'into', 'a', 'single', 'data', 'frame,', 'and', 'scikit-learn', '(Pedregosa', 'et', 'al.,', '2011)', 'was', 'used', 'to', 'scale', 'the', 'data.', 'To', 'better', 'separate', 'the', 'domains,', 'k-mer', 'composition', 'vectors', 'were', 'multiplied', 'by', '2', 'for', 'archaeal', 'species', 'and', 'by', '3', 'for', 'eukaryotic', 'species.', 'The', 'umap.UMAP', 'function', 'was', 'used', 'to', 'then', 'calculate', 'the', 'UMAP', 'with', 'parameters', 'n_neighbors=15,', 'min_dist=0.5,', 'and', 'default', 'parameters', 'otherwise', '(McInnes', 'et', 'al.,', '2018).', '4.3.', 'Prediction', 'evaluations', '4.3.1.', 'Effect', 'of', 'mutations', 'on', 'Evo', '2', 'likelihoods', 'around', 'start', 'codons', 'Referencegenomesequencesandtheirannotationsfor20prokaryoticand16eukaryoticspecieswereobtained', 'from', 'NCBI.', 'From', 'the', 'annotations', 'of', 'each', 'species,', '1,024', 'protein-coding', 'genes', 'were', 'randomly', 'sampled,', 'with', 'the', 'exception', 'of', 'N.', 'equitans,', 'for', 'which', 'all', 'of', 'its', '536', 'protein-coding', 'genes', 'were', 'selected.', 'For', 'each', 'of', 'these', 'sampled', 'genes,', 'we', 'selected', 'genomic', 'coordinates', 'ranging', 'from', '-20nt', 'to', '+20nt', 'from', 'the', 'first', 'base', 'of', 'the', 'start', 'codon,andmutatedthewildtypebaseofeachpositiontoeachofthethreealternativebasestointroduceSNVs.', 'Then,', 'using', 'the', 'Evo', '2', '7B', 'model,', 'we', 'calculated', 'the', 'difference', 'in', 'the', 'likelihoods', 'of', 'the', 'SNVs', 'to', 'their', 'respective', 'wildtype', 'sequences,', 'both', 'of', 'which', 'included', 'the', 'genomic', 'context', 'of', 'a', '8,192nt', 'window', 'that', 'is', 'centered', 'around', 'the', 'mutated', 'nucleotide.', 'In', 'calculating', 'the', 'log', 'likelihoods', 'of', 'both', 'wildtype', 'sequences', 'and', 'their', 'SNVs,', 'we', 'used', 'the', 'average', 'likelihoods', 'of', 'the', 'original', 'sequence', 'and', 'its', 'reverse', 'complement.', 'These', 'delta', 'likelihoods', 'were', 'averaged', 'across', 'the', '1,024', 'sampled', 'genes', 'per', 'each', 'position', 'for', 'each', 'species.', 'The', 'same', 'process', 'was', 'used', 'for', 'the', 'variant', 'effects', 'around', 'stop', 'codons.', 'The', 'phylogenetic', 'trees', 'for', 'both', 'prokaryotic', 'and', 'eukaryotic', 'species', 'were', 'constructed', 'using', 'existing', 'literature', '(Hug', 'et', 'al.,', '2016;Hartmann', 'et', 'al.,', '2006;Hedges,', '2002).', '4.3.2.', 'Effect', 'of', 'prokaryotic', 'mutations', 'on', 'Evo', '2', 'likelihoods', 'We', 'systematically', 'introduced', 'artificial', 'mutations', 'across', 'different', 'genomic', 'regions', 'in', 'prokaryotic', 'genomes.', 'Annotated', 'reference', 'genomes', 'of', '20', 'prokarytoic', 'species', 'shown', 'below', 'were', 'obtained', 'through', 'NCBI.', '•Escherichia', 'coli', '(GCF_000005845.2)', '•Bacillus', 'subtilis', '(GCF_000009045.1)', '•Synechocystis', 'sp.', 'PCC', '(GCF_000019485.1)', '•Mycobacterium', 'tuberculosis', '(GCF_002357975.1)', '•Bacteroides', 'thetaiotaomicron', '(GCF_001314975.1)', '•Methanococcus', 'maripaludis', '(GCF_002945325.1)', '•Nitrosopumilus', 'maritimus', '(GCF_000018465.1)', '•Acinetobacter', 'baumannii', '(GCF_001628795.1)', '•Enterococcus', 'faecium', '(GCF_009734005.1)', '•Klebsiella', 'pneumoniae', '(GCF_000968155.1)', '•Neisseria', 'gonorrhoeae', '(GCF_023822665.1)', '•Neisseria', 'meningitidis', '(GCF_015679665.1)', '•Pseudomonas', 'aeruginosa', '(GCF_000626655.2)', '•Staphylococcus', 'aureus', '(GCF_003609855.1)', '•Methanocaldococcus', 'jannaschii', '(GCF_000091665.1)', '•Sulfolobus', 'solfataricus', '(GCF_000968435.2)', '•Haloferax', 'volcanii', '(GCF_010692905.1)', '•Thermococcus', 'kodakarensis', '(GCF_028471865.1)', '•Nanoarchaeum', 'equitans', '(GCF_000008085.1)', '•Streptomyces', 'coelicolor', '(GCF_008931305.1)', 'For', 'each', 'species,', '5,000', 'positions', 'were', 'randomly', 'sampled', 'from', 'bases', 'annotated', 'as', 'coding', 'regions,', 'and', '2,000', 'positions', 'each', 'were', 'sampled', 'from', 'bases', 'within', 'loci', 'annotated', 'as', 'rRNAs,', 'tRNAs,', 'and', 'ncRNAs,', 'respec-', 'tively.', 'Positions', 'not', 'annotated', 'as', 'CDS,', 'rRNA,', 'tRNA,', 'or', 'ncRNA', 'were', 'considered', 'to', 'be', 'intergenic', 'regions,', 'from', '25.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'which', '2,000', 'positions', 'were', 'sampled', 'for', 'each', 'species.', 'Centered', 'around', 'each', 'sampled', 'position,', 'a', '8,192', 'bp', 'window', 'was', 'used', 'as', 'the', 'genomic', 'context', 'for', 'the', 'calculation', 'of', 'likelihoods', 'with', 'Evo', '7B.', 'For', 'each', 'sampled', 'po-', 'sition', 'in', 'the', 'CDS,', 'the', 'wildtype', 'base', 'was', 'mutated', 'to', 'each', 'of', 'the', 'three', 'alternative', 'bases', 'to', 'introduce', 'SNVs,', 'and', 'deleted', 'for', 'the', '1', 'bp', 'deletion', 'mutant.', 'For', 'each', 'sampled', 'position', 'in', 'rRNA,', 'tRNA,', 'ncRNA,', 'or', 'intergenic', 'regions,', 'the', '10', 'bp', 'window', 'surrounding', 'the', 'position', 'was', 'deleted', 'for', 'the', '10', 'bp', 'deletion', 'variant.', 'For', 'the', 'deletion', 'vari-', 'ants,', 'the', '8,192', 'bp', 'window', 'was', 'extended', 'into', 'the', 'neighboring', 'sequences', 'to', 'match', 'the', 'length', 'of', 'the', 'wildtype', 'sequence', '(8,192', 'bp)', 'to', 'avoid', 'any', 'biases', 'in', 'the', 'likelihoods', 'that', 'arise', 'from', 'differences', 'in', 'sequence', 'lengths.', 'Whether', 'an', 'SNV', 'in', 'the', 'coding', 'region', 'was', 'synonymous,', 'missense,', 'or', 'a', 'nonsense', 'mutation', 'was', 'determined', 'using', 'the', 'standard', 'codon', 'table', 'for', 'all', 'species.', '4.3.3.', 'Effect', 'of', 'eukaryotic', 'mutations', 'on', 'Evo', '2', 'likelihoods', 'We', 'systematically', 'introduced', 'artificial', 'mutations', 'across', 'different', 'genomic', 'regions', 'in', 'eukaryotic', 'genomes.', 'Gene', 'annotations', 'were', 'extracted', 'from', 'GFF3', 'and', 'GTF', 'files', 'obtained', 'through', 'Ensembl', '(Harrison', 'et', 'al.,', '2024)', 'or', 'NCBI.', 'Reference', 'genome', 'sequences', 'for', '16', 'eukaryotic', 'species', 'were', 'used:', '•Arabidopsis', 'thaliana', '(GCF_000001735.4)', '•Caenorhabditis', 'elegans', '(GCA_000002985.3)', '•Callithrix', 'jacchus', '(GCA_011100555.1)', '•Chlamydomonas', 'reinhardtii', '(GCA_000002595.3)', '•Drosophila', 'melanogaster', '(GCF_000001215.4)', '•Danio', 'rerio', '(GCA_000002035.4)', '•Homo', 'sapiens', '(GCF_000001405.40)', '•Macaca', 'mulatta', '(GCF_003339765.1)', '•Mus', 'musculus', '(GCF_000001635.27)', '•Nicotiana', 'attenuata', '(GCA_001879085.1)', '•Oryza', 'sativa', '(GCA_001433935.1)', '•Paramecium', 'tetraurelia', '(GCA_000165425.1)', '•Saccharomyces', 'cerevisiae', '(GCA_000146045.2)', '•Thalassiosira', 'pseudonana', '(GCA_000149405.2)', '•Tetrahymena', 'thermophila', '(GCA_000189635.1)', '•Xenopus', 'tropicalis', '(GCF_000004195.4)', 'Mutations', 'were', 'generated', 'in', 'coding', 'sequences,', 'including', 'synonymous', 'substitutions,', 'nonsynonymous', 'sub-', 'stitutions,', 'premature', 'stop', 'codons,', 'and', 'single', 'nucleotide', 'deletions', '(frameshift).', 'Noncoding', 'regions', 'include', '5′', 'UTRs,', '3′UTRs,', 'introns,', 'intergenic', 'sequences,', 'and', 'noncoding', 'RNA', 'exons', 'annotated', 'as', 'lncRNA', '(lncRNA,', 'lin-', 'cRNA,', 'or', 'lnc_RNA),', 'snoRNA,', 'miRNA', '(miRNA,', 'pre_miRNA),', 'snRNA,', 'tRNA', '(tRNA', 'or', 'source=trnascan),', 'rRNA,', 'or', 'ncRNA', '(ncRNA', 'or', 'ncRNA_gene).', 'Noncoding', 'regions', 'were', 'mutated', 'with', '10', 'bp', 'deletions.', '8,192', 'bp', 'of', 'se-', 'quence', 'context', 'around', 'each', 'mutation', 'position', 'were', 'used,', 'and', 'additional', 'flanking', 'sequence', 'was', 'appended', 'to', 'theendsofthesequenceinthecaseofdeletionstokeepthelengthofthesequencesconsistent.', 'Species-specific', 'codon', 'tables', 'were', 'used', 'to', 'identify', 'appropriate', 'premature', 'stop', 'codons', 'and', 'substitutions.', 'Up', 'to', '200,000', 'se-', 'quences', 'were', 'sampled', 'across', 'sequence', 'types', 'to', 'maintain', 'balanced', 'representation.', 'For', 'each', 'unique', 'region', 'coordinate', '(i.e.', 'a', 'specific', 'exon', 'or', 'intron)', 'up', 'to', '20', 'distinct', 'mutations', 'were', 'retained.', 'For', 'each', 'region', 'and', 'mutation', 'type,', 'the', 'median', 'change', 'in', 'likelihood', 'was', 'calculated', 'as', 'the', 'representative', 'change', 'in', 'likelihood.', '4.3.4.', 'Stop', 'codon', 'analysis', 'across', 'genetic', 'codes', 'To', 'test', 'the', 'ability', 'of', 'the', 'Evo', '2', 'model', 'to', 'understand', 'variations', 'in', 'the', 'genetic', 'code', 'usage', 'across', 'different', 'species,', 'we', 'introduced', 'premature', 'stop', 'codons', 'into', 'coding', 'sequences', 'across', '5', 'species:', 'Arabidopsis', 'thaliana', '(GCF_000001735.4,', 'standard', 'code),', 'Homo', 'sapiens', '(GCF_000001405.40,', 'standard', 'code),', 'Mycoplasma', 'pneu-', 'moniae(GCF_900660465.1,', 'mycoplasma', 'code),', 'Thalassiosira', 'pseudonana', '(GCA_000149405.2,', 'ciliate', 'code),', 'andTetrahymena', 'thermophila', '(GCA_000189635.1,', 'ciliate', 'code).', 'GFF3', 'and', 'GTF', 'annotation', 'files', 'were', 'used', 'to', 'identify', 'coding', 'sequences.', 'Coding', 'sequences', 'and', 'mutation', 'positions', 'were', 'randomly', 'selected,', 'filtering', 'out', 'pseudogenes', 'and', 'sequences', 'shorter', 'than', 'a', 'minimum', 'length', 'threshold', 'of', '10.', 'For', 'each', 'selected', 'coding', 'sequence,', 'randomly', 'selected', 'codons', 'were', 'replaced', 'with', 'seven', 'different', 'stop', 'codons', '(TAA,', 'TAG,', 'TGA,', 'AGG,', 'TCA,', 'AGA,', 'TTA).', 'Sequences', 'were', 'randomly', 'subsampled', 'to', 'at', 'most', '200,000', 'per', 'genome.', 'The', 'likelihood', 'of', '26.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'the', 'reference', 'sequence', 'and', 'mutated', 'sequences', 'was', 'calculated', 'with', 'the', 'Evo2', '7B', 'model', 'with', 'sequence', 'context', 'windows', 'ranging', 'from', '100', 'to', '8,192', 'base', 'pairs', 'centered', 'on', 'the', 'mutation', 'site.', 'The', 'change', 'in', 'likelihood', 'was', 'calculated', 'for', 'each', 'mutation,', 'and', 'the', 'median', 'of', 'these', 'values', 'for', 'each', 'codon', 'was', 'calculated', 'for', 'each', 'species.', 'These', 'median', 'values', 'were', '𝑧', '-score', 'standardized', 'across', 'all', '7', 'tested', 'codons.', '4.3.5.', 'Noncoding', 'regulatory', 'sequence', 'evaluations', '(DART-Eval)', 'For', 'zero-shot', 'evaluations', 'in', 'DART-Eval', '(Patel', 'et', 'al.,', '2024),', 'we', 'assessed', 'model', 'performance', 'on', 'Task', '1', '(CCRE),', 'Task', '2', '(TF', 'Motif),', 'and', 'Task', '5', '(Variant', 'Effect', 'Prediction).', 'Tasks', '1', 'and', '2', 'focused', 'on', 'likelihood-based', 'eval-', 'uations:', 'Task', '1', 'involved', 'distinguishing', 'candidate', 'cis-regulatory', 'elements', '(cCREs)', 'from', 'shuffled', 'control', 'se-', 'quences,', 'using', 'a', 'dataset', 'of', 'over', '2.3', 'million', 'sequences', 'derived', 'from', 'experimentally', 'validated', 'regulatory', 're-', 'gions,', 'while', 'Task', '2', 'aimed', 'to', 'identify', 'transcription', 'factor', '(TF)', 'motifs', 'by', 'differentiating', 'true', 'TF', 'binding', 'sites', 'from', 'control', 'sequences,', 'utilizing', 'a', 'dataset', 'of', 'approximately', '577,000', 'sequences', 'from', 'TF', 'footprinting', 'experi-', 'ments.', 'Task', '5', 'evaluated', 'variant', 'effects', 'through', 'both', 'likelihood-based', 'and', 'embedding-based', 'analyses.', 'This', 'task', 'included', 'two', 'datasets:', 'one', 'examining', 'chromatin', 'accessibility', 'QTLs', '(CaQTLs)', 'across', 'African', 'populations,', 'with', 'over', '219,000', 'variant', 'sites,', 'and', 'another', 'focusing', 'on', 'Yoruba', 'dynamic', 'sequence', 'QTLs', '(dsQTLs),', 'with', 'approximately', '28,000', 'sites.', 'For', 'the', 'embedding-based', 'analysis,', 'Evo', '2', 'embeddings', 'were', 'first', 'extracted', 'from', 'Block', '13,', 'which', 'was', 'randomly', 'selected', 'for', 'both', 'the', '7B', 'and', '40B', 'models.', 'Additionally,', 'Block', '27', 'was', 'then', 'chosen', 'for', 'the', 'Evo', '2', '7B', 'model', 'while', 'Block', '20', 'was', 'selected', 'for', 'the', 'Evo', '2', '40B', 'model', 'due', 'to', 'their', 'superior', 'performance', 'on', 'the', 'BRCA1variant', 'supervised', 'classification', 'task', '(see', 'Section', '4.3.16).', 'We', 'selected', 'these', 'tasks', 'to', 'emphasize', 'Evo', '2’s', 'zero-shot', 'capabilities', 'for', 'regulatory', 'sequence', 'prediction', 'across', 'various', 'data', 'types.', 'Resultsacrossallthreetaskswerecomparedtopre-computedresultsfromtestingvariousmodelsintheDART-', 'Eval', 'paper,', 'including', 'GENA-LM', '(bert-large-t2t),', 'HyenaDNA', '(large-1m),', 'DNABERT-2', '(117M),', 'and', 'NT', '500M', '(v2-500m-multi-species).', '4.3.6.', 'Zero-shot', 'protein', 'fitness', 'prediction', 'We', 'conducted', 'zero-shot', 'fitness', 'prediction', 'for', 'protein', 'and', 'ncRNA', 'sequences', 'as', 'described', 'in', 'Nguyen', 'et', 'al.', '(2024a).', 'We', 'previously', 'compiled', 'nine', 'datasets', 'of', 'prokaryotic', 'DMS', 'datasets', 'from', 'ProteinGym', 'in', 'which', 'the', 'original', 'study', 'authors', 'had', 'provided', 'readily', 'accessible', 'nucleotide', 'and', 'protein', 'sequences:', 'a', '𝛽', '-lactamase', 'DMS', 'by', 'Firnberg', 'et', 'al.,', 'a', '𝛽', '-lactamase', 'DMS', 'by', 'Jacquier', 'et', 'al.,', 'a', 'CcdB', 'DMS,', 'a', 'multiprotein', 'thermostability', 'dataset,', 'anIF-1DMS,anRncDMS,anHaeIIIDMS,aVIM-2DMS,andanAPH(3′)IIDMS.See', 'ProteinGym', '(Notinetal.,', '2023)', 'for', 'a', 'list', 'of', 'references', 'to', 'these', 'studies.', 'We', 'also', 'compiled', 'six', 'datasets', 'of', 'human', 'proteins', 'from', 'Livesey', 'and', 'Marsh', '(2023)', 'in', 'which', 'the', 'original', 'study', 'authors', 'had', 'provided', 'readily', 'accessible', 'nucleotide', 'and', 'protein', 'sequences:', 'a', 'CBS', 'DMS,', 'a', 'GDI1', 'DMS,', 'a', 'PDE3A', 'DMS,', 'a', 'P53', 'DMS', 'by', 'Kotler', 'et', 'al.,', 'a', 'P53', 'DMS', 'by', 'Giacomelli', 'et', 'al.,', 'and', 'a', 'BRCA1', 'DMS.', 'See', 'Livesey', 'and', 'Marsh', '(2023)', 'for', 'references', 'to', 'these', 'studies.', 'For', 'this', 'study,', 'we', 'also', 'compiled', 'a', 'set', 'of', '18', 'DMS', 'datasets', 'corresponding', 'to', 'proteins', 'from', 'viruses', 'that', 'infect', 'humans:', 'an', 'HCV', 'polymerase', 'DMS', 'by', 'Qi', 'et', 'al.,', 'an', 'influenza', 'hemagglutinin', 'DMS', 'by', 'Wu', 'et', 'al.,', 'an', 'influenza', 'nucleoprotein', 'DMS', 'and', 'a', 'PB1', 'DMS', 'by', 'Doud', 'et', 'al.,', 'an', 'influenza', 'PA', 'DMS', 'by', 'Wu', 'et', 'al.,', 'an', 'influenza', 'neuraminidase', 'DMS', 'by', 'Jiang', 'et', 'al.,', 'an', 'HIV-1', 'TAT', 'DMS', 'and', 'an', 'HIV-1', 'REV', 'DMS', 'by', 'Fernandes', 'et', 'al.,', 'an', 'HIV-1', 'envelopeDMSbyHaddoxetal.,anHIV-1envelopeDMSbyDuenas-Decampetal.,aninfluenzahemagglutinin', 'DMS', 'by', 'Lee', 'et', 'al.,', 'an', 'HIV-1', 'envelope', 'DMS', 'by', 'Haddox', 'et', 'al.,', 'an', 'influenza', 'PB2', 'DMS', 'by', 'Soh', 'et', 'al.,', 'a', 'Zika', 'envelope', 'DMS', 'by', 'Sourisseau', 'et', 'al.,', 'a', 'SARS-CoV-2', 'spike', 'RBD', 'DMS', 'by', 'Starr', 'et', 'al.,', 'a', 'coxsackievirus', 'capsid', 'DMS', 'by', 'Mattenberger', 'et', 'al.,', 'an', 'AAV2', 'capsid', 'DMS', 'by', 'Sinai', 'et', 'al.,', 'a', 'SARS-CoV-2', 'Mpro', 'DMS', 'by', 'Flynn', 'et', 'al.,', 'a', 'dengue', 'virus', 'NS5', 'DMS', 'by', 'Suphatrakul', 'et', 'al.,', 'and', 'an', 'influenza', 'PB1', 'DMS', 'by', 'Li', 'et', 'al.', 'See', 'ProteinGym', '(Notin', 'et', 'al.,', '2023)', 'for', 'a', 'list', 'of', 'references', 'to', 'these', 'studies.', 'For', 'comparing', 'nucleotide', 'and', 'protein', 'language', 'models', 'on', 'bacterial', 'and', 'human', 'DMS', 'datasets,', 'we', 'utilized', 'the', 'complete', 'set', 'of', 'unique', 'nucleotide', 'sequences', 'and', 'their', 'corresponding', 'fitness', 'values', 'exactly', 'as', 'reported', 'in', 'the', 'original', 'studies.', 'When', 'discrepancies', 'arose', 'between', 'fitness', 'values', 'reported', 'for', 'nucleotide', 'sequences', 'versus', 'their', 'protein', 'counterparts,', 'we', 'used', 'the', 'fitness', 'values', 'for', 'the', 'nucleotide', 'sequences;', 'in', 'these', 'cases,', 'we', 'evaluated', 'the', 'protein', 'language', 'models', 'using', 'the', 'translated', 'sequence.', 'For', 'mutations', 'involving', 'stop', 'codons,', 'which', 'were', 'reported', 'in', 'some', 'studies,', 'we', 'included', 'these', 'sequences', 'when', 'evaluating', 'the', 'nucleotide', 'language', 'modelsbutexcludedthemfromtheproteinlanguagemodelbenchmark.', 'Forhumanviralproteins,weusedthe', 'wildtype', 'protein', 'sequence', 'and', 'substitutions', 'as', 'reported', 'by', 'ProteinGym', 'to', 'evaluate', 'protein', 'language', 'models.', '27.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'To', 'evaluate', 'the', 'nucleotide', 'language', 'models', 'on', 'human', 'viral', 'proteins,', 'we', 'manually', 'retrieved', 'the', 'nucleotide', 'sequenceofeachproteinfromtheGenBankentryassociatedwitheachprotein’sUniProtentry.', 'Foreachamino', 'acidsubstitutioninProteinGym,', 'weusedthemostfrequentlyusednucleotidecodoninthehumancodontable', 'corresponding', 'to', 'the', 'mutant', 'amino', 'acid', 'value.', 'To', 'assess', 'model', 'performance,', 'we', 'calculated', 'the', 'Spearman', 'correlation', 'between', 'the', 'experimental', 'fitness', 'values', 'and', 'the', 'model-derived', 'sequence', 'scores.', 'For', 'autoregressive', 'language', 'models,', 'we', 'used', 'sequence', 'like-', 'lihood', 'as', 'the', 'score,', 'while', 'for', 'masked', 'language', 'models,', 'we', 'used', 'sequence', 'pseudolikelihood.', 'We', 'compared', 'the', 'Evo', '2', '40B,', 'Evo', '2', '7B,', 'Evo', '1,', 'GenSLM', '(Zvyagin', 'et', 'al.,', '2023),', 'Nucleotide', 'Transformer', '(Dalla-Torre', 'et', 'al.,', '2024),', 'and', 'RNA-FM', '(Chen', 'et', 'al.,', '2022)', 'nucleotide', 'language', 'models', 'and', 'the', 'CARP-640M', '(Yang', 'et', 'al.,', '2024),', 'ESM-1v', '(Meier', 'et', 'al.,', '2021),', 'ESM-2', '650M,', 'ESM-2', '3B', '(Lin', 'et', 'al.,', '2023),', 'ProGen2-large,', 'and', 'ProGen2-xlarge', '(Nijkamp', 'et', 'al.,', '2023)', 'protein', 'language', 'models.', '4.3.7.', 'Zero-shot', 'ncRNA', 'fitness', 'prediction', 'We', 'previously', 'compiled', 'nine', 'datasets', 'of', 'DMS', 'datasets', 'on', 'ncRNA', '(Nguyen', 'et', 'al.,', '2024a):', 'a', 'ribozyme', 'DMS', 'by', 'Kobori', 'et', 'al.,', 'a', 'ribozyme', 'DMS', 'by', 'Andreasson', 'et', 'al.,', 'a', 'tRNA', 'DMS', 'by', 'Domingo', 'et', 'al.,', 'a', 'tRNA', 'DMS', 'by', 'Guy', 'et', 'al.,', 'aribozymeDMSbyHaydenetal.,aribozymeDMSbyPittetal.,andarRNAmutagenesisstudybyZhangetal.', 'SeeNguyen', 'et', 'al.', '(2024a)', 'for', 'a', 'list', 'of', 'references', 'to', 'these', 'studies.', 'To', 'assess', 'model', 'performance,', 'we', 'calculated', 'theSpearmancorrelationbetweentheexperimentalfitnessvaluesandthemodel-derivedsequencescores.', 'For', 'autoregressivelanguagemodels,weusedsequencelikelihoodasthescore,whileformaskedlanguagemodels,', 'we', 'used', 'sequence', 'pseudolikelihood.', 'We', 'compared', 'the', 'Evo', '2', '40B,', 'Evo', '2', '7B,', 'Evo', '1,', 'GenSLM,', 'Nucleotide', 'Transformer,', 'RNA-FM,', 'RNAErnie', '(Wang', 'et', 'al.,', '2024),', 'and', 'RiNALMo', '(Penić', 'et', 'al.,', '2024)', 'nucleotide', 'language', 'models.', '4.3.8.', 'Zero-shot', 'mRNA', 'decay', 'evaluation', 'Forthisevaluation,weusedahumancelllinedatasetthatleveragesmetabolicRNAlabelingtoestimatemRNA', 'decay', 'rates', 'across', 'the', 'transcriptome.', 'We', 'used', 'the', 'average', 'values', 'across', 'the', 'reported', 'lines', 'as', 'a', 'measure', 'of', 'overall', 'mRNA', 'decay', 'rates.', 'We', 'then', 'used', 'the', 'Evo', '2', '40B', 'and', '7B', 'models,', 'along', 'with', 'Nucleotide', 'Transformer,', 'RNA-FM,andRiNALMotocomparesequencescorestomRNAdecayrates.', 'Forinputstoeachmodel,', 'weeither', 'used', 'the', 'full-length', 'mRNA', 'or', 'the', 'longest', 'context', 'allowed', 'by', 'the', 'model', 'from', 'the', 'end', 'of', 'the', 'transcript.', 'Since', 'model', 'scores', 'may', 'be', 'confounded', 'by', 'sequence', 'length,', 'we', 'first', 'applied', 'loess', 'regression', 'to', 'correct', 'for', 'variations', 'in', 'transcript', 'length.', '4.3.9.', 'Exon/intron', 'classification', 'To', 'evaluate', 'model', 'embeddings’', 'ability', 'to', 'classify', 'genomic', 'positions', 'as', 'exonic', 'or', 'intronic', 'across', 'diverse', 'eu-', 'karyotes,', 'we', 'selected', '94', 'available', 'eukaryotic', 'species', 'from', 'PANTHER19.0', '(Mi', 'et', 'al.,', '2013).', 'We', 'partitioned', 'organisms', 'into', 'training', '(80%),', 'hyperparameter', 'optimization', '(10%),', 'and', 'test', '(10%)', 'sets,', 'with', 'Homo', 'sapi-', 'ens,Mus', 'musculus,', 'and', 'Danio', 'rerio', 'manually', 'assigned', 'to', 'the', 'test', 'set', 'after', 'random', 'partitioning.', 'Trichomonas', 'vaginalis', 'andLeishmania', 'major,', 'originally', 'in', 'the', 'test', 'set,', 'were', 'excluded', 'from', 'evaluation', 'due', 'to', 'insufficient', 'intronic', 'annotations.', 'All', 'computations', 'were', 'performed', 'on', 'a', 'single', 'NVIDIA', 'H100', 'Tensor', 'Core', 'GPU.', 'Model', 'versions', 'used', 'were', 'evo2_7b_gen', 'for', 'Evo', '2,', 'evo-1-8k-base', 'for', 'Evo', '1', '(Nguyen', 'et', 'al.,', '2024a),', 'and', 'nucleotide-', 'transformer-2.5b-multi-species', 'for', 'Nucleotide', 'Transformer', '(Dalla-Torre', 'et', 'al.,', '2024).', 'For', 'each', 'species,', 'we', 'randomly', 'sampled', 'positions', 'from', 'NCBI', 'RefSeq-annotated', '(O’Leary', 'et', 'al.,', '2016)', 'long', 'noncoding', 'and', 'protein-coding', 'genes', 'in', 'an', 'unbiased', 'manner.', 'The', 'latest', 'version', 'of', 'RefSeq', 'FASTA', 'and', 'GTF', 'files', 'were', 'downloaded', 'on', 'November', '18th,', '2024.', 'All', 'exon', 'annotations', 'from', 'RefSeq', 'GTF', 'files', 'were', 'included,', 'without', 'distinguishing', 'between', 'constitutive', 'and', 'alternative', 'exons.', 'For', 'each', 'position,', 'we', 'extracted', 'both', 'for-', 'ward', 'and', 'reverse', 'strand', 'sequences', 'from', 'reference', 'genomes', 'up', 'to', 'each', 'model’s', 'maximum', 'length', '(8192', 'bp', 'for', 'Evo', '2', 'and', 'Evo', '1;', '5994', 'bp', 'for', 'Nucleotide', 'Transformer),', 'with', 'the', 'target', 'position', 'at', 'the', '3′end', 'of', 'each.', 'We', 'concatenated', 'the', 'forward', 'and', 'reverse', 'strand', 'embeddings', 'as', 'classifier', 'input', 'after', 'keeping', 'all', 'embedding', 'dimensions', 'and', 'only', 'the', 'final', 'sequence', 'position.', 'We', 'evaluated', 'both', 'linear', 'classifiers', 'and', 'single-hidden', 'layer', 'perceptrons.', 'For', 'initial', 'optimization,', 'we', 'sam-', 'pled', '150', 'positions', 'per', 'species', 'and', 'extracted', 'model', 'embeddings', 'from', 'each', 'model’s', 'top', 'level', 'layers.', 'Using', 'weighted', 'binary', 'cross-entropy', 'loss,', 'we', 'trained', 'classifiers', 'for', 'all', 'layers', 'and', 'selected', 'the', 'best', 'performing', 'layer', '28.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'based', 'on', 'validation', 'accuracy.', 'We', 'then', 'optimized', 'hyperparameters', '(number', 'of', 'hidden', 'layers', '(0', 'or', '1),', 'hid-', 'den', 'layer', 'dimension,', 'learning', 'rate,', 'batch', 'size,', 'and', 'weight', 'decay)', 'using', 'Tree-structured', 'Parzen', 'Estimators', '(TPE)', 'on', 'the', 'selected', 'layer,', 'choosing', 'the', 'configuration', 'that', 'maximized', 'validation', 'accuracy.', 'For', 'Evo', '2', '-', 'layer:', 'blocks.26,', 'number', 'of', 'hidden', 'layers:', '1,', 'hidden', 'layer', 'dimension:', '1024,', 'learning', 'rate:', '5×10−5,', 'batch', 'size:', '16,', 'and', 'weight', 'decay:', '2×10−4.', 'For', 'Nucleotide', 'Transformer', '-', 'layer:', '24,', 'number', 'of', 'hidden', 'layers:', '1,', 'hidden', 'layer', 'dimension:', '1024,', 'learning', 'rate:', '5×10−4,', 'batch', 'size:', '64,', 'and', 'weight', 'decay:', '2×10−7.', 'For', 'Evo', '1', '-', 'layer:', 'blocks.3,', 'number', 'of', 'hidden', 'layers:', '0,', 'learning', 'rate:', '5×10−5,', 'batch', 'size:', '64,', 'and', 'weight', 'decay:', '1.5×10−6.', 'Final', 'classifiers', 'were', 'trained', 'on', '1500', 'positions', 'per', 'species', 'using', 'these', 'optimal', 'parameters.', '4.3.10.', 'Gene', 'essentiality', 'We', 'conducted', 'zero-shot', 'gene', 'essentiality', 'prediction', 'as', 'previously', 'described', '(Nguyen', 'et', 'al.,', '2024a).', 'We', 'ob-', 'tained', 'binary', 'essentiality', 'data', '(labeled', 'as', '“essential”', 'or', '“nonessential”)', 'for', '56', 'bacterial', 'genomes', 'from', 'the', 'DEG', 'database', '(Zhang,', '2004).', 'Additionally,', 'we', 'incorporated', 'genome-wide', 'essentiality', 'data', 'for', 'two', 'phage', 'genomes,', 'lambda', 'and', 'P1,', 'from', 'Piya', 'et', 'al.', '(2023),', 'using', 'the', 'binary', 'labels', 'that', 'the', 'study', 'authors', 'assigned', 'based', 'on', 'their', 'CRISPRi', 'screen', 'results.', 'To', 'conduct', 'our', 'in', 'silico', 'gene', 'essentiality', 'screen,', 'we', 'accessed', 'the', 'complete', 'bacterial', 'genomes', 'using', 'DEG-', 'provided', 'RefSeq', 'IDs.', 'For', 'the', 'phage', 'genomes,', 'we', 'used', 'RefSeq:', 'NC_001416', '(lambda', 'phage)', 'and', 'RefSeq:', 'NC_005856', '(P1', 'phage)', 'as', 'reference', 'genomes.', 'We', 'provided', 'the', 'model', 'with', 'gene', 'sequence', 'plus', 'symmetric', 'context', 'totaling', '8,192', 'bp', '(equal', 'distribution', 'on', 'both', 'sides).', 'For', 'genes', 'exceeding', '8,192', 'bp', 'in', 'length,', 'we', 'utilized', 'only', 'the', 'first', '8,192', 'bp', 'of', 'the', 'sequence.', 'We', 'calculated', 'scores', 'by', 'determining', 'the', 'difference', 'in', 'log-likelihoods', 'between', 'mutated', 'and', 'wildtype', 'se-', 'quences.', 'Our', 'mutation', 'strategy', 'involved', 'inserting', 'multiple', 'stop', 'codons', '(“TAATAATAATAGTGA”)', 'at', 'a', '12-', 'nucleotide', 'offset', 'into', 'the', 'coding', 'sequence.', 'We', 'evaluated', 'the', 'Evo', '2', '40B,', 'Evo', '2', '7B,', 'and', 'Evo', '1', '131k', 'models', 'using', 'this', 'strategy.', 'We', 'also', 'used', 'the', 'gene’s', 'linear', 'position', 'in', 'the', 'reference', 'genome', 'as', 'a', 'predictive', 'value', 'for', 'essentialitytocontrolforpotentialpositionalbiasinthemodel’spredictions.', 'Weassessedgeneconservationas', 'anothercontrol.', 'WefirstextractedallproteinsequencesfromtheOpenGenome1dataset,performedanall-by-', 'all', 'sequence', 'search', '(using', 'mmseqs', 'easy-search', 'with', 'default', 'parameters)', 'between', 'proteins', 'and', 'OpenGenome', 'proteins,', 'counted', 'the', 'number', 'of', 'significant', 'hits', '(E-value', 'threshold', 'of', '1', '×10−2),', 'and', 'used', 'higher', 'hit', 'counts', 'as', 'an', 'approximation', 'of', 'greater', 'conservation', 'and', 'potential', 'essentiality.', 'We', 'evaluated', 'the', 'predictive', 'power', 'of', 'the', 'log-likelihood', 'changes', '(and', 'control', 'experiments)', 'for', 'binary', 'gene', 'essentiality', 'using', 'the', 'AUROC', 'score.', '4.3.11.', 'lncRNA', 'essentiality', 'Essential', 'lncRNA', 'genes', 'were', 'recently', 'identified', 'in', 'a', 'Cas13', 'knockdown', 'experiment', 'of', 'lncRNA', 'transcripts', 'in', '5', 'different', 'cell', 'lines', '(HAP1,', 'HEK293FT,', 'K562,', 'MDA-MB-231,', 'and', 'THP1)', '(Liang', 'et', 'al.,', '2024).', 'This', 'included', 'a', 'total', 'of', '778', 'genes', 'that', 'were', 'essential', 'in', 'one', 'or', 'more', 'cell', 'lines,', 'and', '46', 'that', 'were', 'essential', 'in', 'all', '5', 'cell', 'lines.', 'Human', 'lncRNA', 'gene', 'annotations', 'were', 'collected', 'from', 'a', 'previous', 'publication', '(Sarropoulos', 'et', 'al.,', '2019).', 'Cas13guidesequencebindingsiteswereusedasmutationpositions,', 'with100bpofsequencebeingscrambled', 'around', 'the', 'genomic', 'Cas13', 'mutation', 'position,', 'and', 'up', 'to', '6,000', 'bp', '(Nucleotide', 'Transformer)', 'or', '8,192', 'bp', '(Evo', '2', 'models)', 'of', 'surrounding', 'flanking', 'sequence', 'were', 'extracted.', '97.7%', '(48,310', 'out', 'of', '49,441)', 'of', 'Cas13', 'guide', 'sequences', 'were', 'mapped', 'to', 'their', 'corresponding', 'lncRNA', 'gene', 'genomic', 'position.', 'The', 'lncRNA', 'transcripts', 'were', 'also', 'scrambled', 'at', 'guide', 'positions', 'and', 'analyzed', 'separately.', 'The', 'difference', 'in', 'log-likelihoods', 'for', 'reference', 'and', 'mutated', 'sequences', 'were', 'then', 'calculated', 'using', 'Evo', '2', '7B,', 'Evo', '2', '40B,', 'and', 'nucleotide', 'transformer', '2.5B', 'multi-', 'species.', 'The', 'average', 'difference', 'in', 'log-likelihood', 'for', 'each', 'gene', 'was', 'used', 'as', 'the', 'final', 'change', 'in', 'log-likelihood', 'value', 'for', 'each', 'gene.', 'These', 'values', 'were', 'then', 'used', 'as', 'a', 'predictive', 'variable', 'in', 'a', 'logistic', 'regression', 'model', 'of', 'gene', 'essentiality,', 'and', 'directly', 'compared', 'to', 'simple', 'genetic', 'metrics', 'such', 'as', 'GC', 'content', 'and', 'transcript', 'length.', 'Gene', 'age', 'values', 'from', 'the', 'original', 'lncRNA', 'essentiality', 'study', '(Sarropoulos', 'et', 'al.,', '2019)', 'were', 'used', 'where', 'available', 'as', 'an', 'additional', 'control.', '4.3.12.', 'Zero-shot', 'variant', 'scoring', 'We', 'compare', 'different', 'models’', 'ability', 'to', 'score', 'mutations,', 'zero-shot,', 'by', 'taking', 'the', 'delta', 'between', 'the', 'predicted', 'mutant', 'and', 'reference', 'log', 'likelihoods.', 'DNA', 'models', 'use', 'the', 'DNA', 'sequence', 'around', 'the', 'variant', 'while', 'protein', 'models', 'are', 'scored', 'using', 'the', 'amino', 'acid', 'sequence', 'of', 'the', 'gene.', 'For', 'indels,', 'we', 'also', 'normalized', 'to', 'the', 'reference', '29.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'sequence,', 'and', 'for', 'DNA', 'models', 'to', 'keep', 'the', 'change', 'in', 'likelihood', 'invariant', 'to', 'length', 'we', 'maintain', 'the', 'total', 'length', 'of', 'sequence', 'scored', 'to', 'be', 'the', 'same', 'regardless', 'of', 'the', 'length', 'of', 'the', 'indel', 'by', 'centering', 'on', 'the', 'indel', 'and', 'adding', 'or', 'removing', 'context', 'nucleotides', 'on', 'the', 'edges', 'of', 'the', 'window.', 'Variants', 'assigned', 'a', 'more', 'negative', 'log-likelihood', 'change', 'from', 'reference', 'are', 'considered', 'to', 'be', 'more', 'deleterious.', 'Across', 'the', 'various', 'evaluations,', 'we', 'used', 'the', 'following', 'models', 'for', 'comparisons:', 'CADD', '(Schubach', 'et', 'al.,', '2024),', 'GPN-MSA', '(Benegas', 'et', 'al.,', '2023),', 'PhyloP', '(Pollard', 'et', 'al.,', '2010),', 'Nucleotide', 'Transformer', '2.5B', 'multi-species', '(Dalla-Torre', 'et', 'al.,', '2024),', 'Evo', '1', '(Nguyen', 'et', 'al.,', '2024a),', 'RNA-FM', '(Shen', 'et', 'al.,', '2024),', 'EnCodon/DeCodon', '(Naghipourfar', 'et', 'al.,', '2024),', 'CodonBERT(Lietal.,', '2023),ESM-1b(Rivesetal.,', '2021),ESM-2(Linetal.,', '2023),andAlphaMissense(Cheng', 'et', 'al.,2023).', 'To', 'score', 'a', 'variant', 'with', 'Evo', '2,', 'we', 'take', 'a', 'genomic', 'window', 'of', 'length', '8,192', 'around', 'the', 'variant', 'and', 'calcu-', 'late', 'the', 'likelihood', 'of', 'the', 'variant', 'sequence', 'divided', 'by', 'the', 'likelihood', 'of', 'the', 'reference', 'sequence', 'at', 'the', 'same', 'position.', 'For', 'encoder', 'models,', 'we', 'applied', 'a', 'position-wise', 'masking', 'to', 'calculate', 'the', 'pseudolikelihood', 'of', 'the', 'reference', 'sequence', 'normalized', 'to', 'pseudolikelihood', 'of', 'the', 'reference', 'alleles.', 'We', 'use', 'the', 'change', 'in', 'pseudolike-', 'lihood', '(Brandes', 'et', 'al.,', '2023)', 'to', 'score', 'non-SNVs', 'using', 'encoder', 'models', 'such', 'as', 'ESM-1b,', 'ESM-2,', 'and', 'Encodon,', 'but', 'cannot', 'include', 'indels', 'for', 'models', 'with', 'fixed', 'coordinates', 'like', 'GPN-MSA', 'or', 'AlphaMissense.', 'For', 'PhyloP,', 'we', 'use', 'PhyloP100', 'which', 'is', 'built', 'on', 'alignments', 'from', '100', 'vertebrate', 'species.', 'To', 'score', 'non-SNV', 'variants,', 'we', 'take', 'the', 'total', 'of', 'the', 'PhyloP', 'scores', 'at', 'each', 'affected', 'position', 'in', 'the', 'reference.', 'For', 'each', 'benchmark', 'we', 'score', 'the', 'same', 'variants', 'with', 'all', 'models.', '4.3.13.', 'ClinVar', 'variant', 'effect', 'prediction', 'We', 'use', 'ClinVar', 'release', '2024.02.28,', 'a', 'database', 'of', 'expert', 'annotated', 'human', 'disease', 'variants', '(Landrum', 'et', 'al.,', '2013).', 'We', 'remove', 'variants', 'which', 'affect', 'more', 'than', '64', 'base', 'pairs', 'of', 'reference', 'or', 'alternate', 'allele', 'sequence', 'and', 'remove', 'variants', 'of', 'unknown', 'significance', 'from', 'the', 'evaluation.', 'We', 'include', 'only', 'variants', 'on', 'the', 'nuclear', 'genome,', 'with', 'a', 'review', 'status', 'of', 'at', 'least', 'two', 'stars', '(i.e.,', 'at', 'least', 'multiple', 'submitters', 'provided', 'evidence', 'or', 'an', 'expert', 'panel', 'reviewed', 'the', 'variant),', 'and', 'subset', 'to', 'loci', 'with', 'matched', 'transcript_ids', 'in', 'GRCh38.p14', 'GTF', 'file.', 'Usingmodelscores,weclassifyPathogenic/LikelyPathogenicvariantsfromBenign/LikelyBenignvariants,', 'evaluating', 'using', 'AUROC', 'and', 'AUPRC.', 'We', 'calculate', 'statistics', 'for', 'coding,', 'noncoding,', 'both', 'for', 'SNV', 'and', 'non-', 'SNV,', 'to', 'enable', 'comparison', 'with', 'specialized', 'models', 'that', 'only', 'support', 'coding', 'variants', 'or', 'only', 'support', 'scoring', 'SNV.', '4.3.14.', 'SpliceVarDB', 'variant', 'effect', 'prediction', 'Weused', 'SpliceVarDB,adatabase', 'ofexperimentallyvalidated', 'splicevariantsinhumans', '(Sullivanetal.,', '2024),', 'toclassifymutationsthatcauseaberrantsplicingbasedonzero-shotpredictionofvariousmodels.', 'Weexcluded', 'variants', 'labeled', 'as', '‘low-frequency’', 'in', 'SpliceVarDB.', '4.3.15.', 'BRCA1/2', 'zero-shot', 'classification', 'For', 'all', 'BRCA1andBRCA2SNVs', 'with', 'reported', 'functional', 'scores', 'and', 'classifications,', 'we', 'parsed', 'sequences', 'of', 'a', '8,192bp', 'window', 'around', 'the', 'variant', 'site', 'from', 'the', 'human', 'reference', 'genome', 'used', 'by', 'the', 'respective', 'original', 'studies', '(Findlay', 'et', 'al.,', '2018;Huang', 'et', 'al.,', '2025).', 'For', 'both', 'genes,', 'we', 'used', 'the', 'classification', 'of', 'SNVs', 'made', 'in', 'the', 'original', 'studies', 'to', 'label', 'the', 'SNVs:', 'for', 'BRCA1,', 'SNVs', 'labeled', 'as', '“LOF”', 'were', 'classified', 'as', 'loss', 'of', 'function', 'variants', '(', '𝑁', '=', '823),', 'while', 'SNVs', 'labeled', 'as', '“FUNC”', 'or', '“INT”', 'were', 'labeled', 'as', 'functional/intermediate', 'variants', '(', '𝑁', '=', '3,070);', 'for', 'BRCA2,', 'SNVs', 'labeled', 'as', '“P', 'strong”,', '“P', 'moderate”,', 'and', '“P', 'supporting”', 'were', 'classified', 'as', 'loss', 'of', 'function', 'variants', '(', '𝑁', '=', '1,156),', 'while', 'SNVs', 'labeled', 'as', '“B', 'strong”,', '“B', 'moderate”,', '“B', 'supporting”', 'were', 'classified', 'as', 'functional/intermediate', 'variants', '(', '𝑁', '=', '5,681).', '4.3.16.', 'BRCA1', 'supervised', 'classification', 'For', 'all', 'BRCA1SNVs,', 'we', 'again', 'parsed', 'sequences', 'of', 'a', '8,192', 'bp', 'window', 'around', 'the', 'mutation', 'site', 'using', 'the', 'human', 'reference', 'genome.', 'To', 'identify', 'the', 'best', 'block', 'of', 'Evo', '2', '40B', 'to', 'extract', 'embeddings', 'from', 'for', 'this', 'task,', 'we', 'took', 'embeddings', 'from', 'the', 'pre-normalization', 'layer', 'of', 'each', 'block', 'of', 'the', 'Evo', '2', '40B', 'model', 'for', 'the', 'reference', 'sequence', 'and', 'the', 'SNV.', 'These', 'embeddings', 'were', 'averaged', 'across', 'tokens', 'to', 'yield', 'vectors', 'of', 'length', '8,192', 'for', '30.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'the', 'reference', 'and', 'the', 'variant', 'sequences.', 'These', 'two', 'vectors', 'were', 'concatenated', 'to', 'yield', 'vectors', 'of', 'length', '16,384,whichwereusedasinputstotrainaclassificationmodelthatconsistsofafeed-forwardneuralnetwork', 'with', 'three', 'hidden', 'layers.', 'The', 'neural', 'network', 'takes', 'an', 'input', 'of', 'dimension', '𝐷', 'and', 'processes', 'it', 'through', 'fully', 'connected', 'layers', 'of', 'sizes', '512,', '128,', 'and', '32', 'neurons,', 'respectively,', 'before', 'outputting', 'a', 'probability', 'that', 'the', 'given', 'SNV', 'is', 'pathogenic.', 'Each', 'hidden', 'layer', 'is', 'followed', 'by', 'ReLU', 'activation,', 'batch', 'normalization,', 'and', 'dropout', '(', '𝑝', '=0.3).', 'The', 'final', 'layer', 'uses', 'sigmoid', 'activation', 'to', 'produce', 'binary', 'classification', 'probabilities.', 'The', 'complete', 'architecture', 'is:', 'Input(', '𝐷', ')→Linear(512)→', 'ReLU→BatchNorm→Dropout(0.3)', '→Linear(128)→', 'ReLU→BatchNorm→Dropout(0.3)', '→Linear(32)→', 'ReLU→BatchNorm', '→Linear(1)→', 'Sigmoid', '20%', 'of', 'all', 'BRCA1', 'SNVs', 'were', 'withheld', 'from', 'training', 'as', 'the', 'test', 'set.', '20%', 'of', 'the', 'remaining', 'SNVs', 'were', 'further', 'sequestered', 'as', 'the', 'validation', 'set.', 'The', 'model', 'was', 'trained', 'on', 'the', 'training', 'set', 'using', 'Adam', 'optimization', '(learning', 'rate:', '3×10−4,', 'batch', 'size:', '128).', 'Training', 'employed', 'early', 'stopping', '(patience:', '100),', 'learning', 'rate', 'reductiononplateau(factor:', '0.5,', 'patience:', '20,', 'min_lr:', '1×10−6),', 'andgradientclipping(maxnorm:', '1.0).', 'The', 'model', 'was', 'trained', 'for', 'up', 'to', '500', 'epochs', 'using', 'binary', 'cross-entropy', 'loss,', 'with', 'the', 'best-performing', 'model', 'on', 'validationdataselectedforfinalevaluation.', 'Themodeltrainedwiththeembeddingsfromblock20performed', 'the', 'best', 'on', 'the', 'test', 'set', '(AUROC', '=', '0.92),', 'which', 'led', 'us', 'to', 'choose', 'this', 'layer', 'for', 'the', 'next', 'step.', 'In', 'the', 'next', 'step,', 'for', 'each', 'SNV,', 'we', 'created', 'a', 'feature', 'vector', 'by', 'extracting', 'embeddings', 'from', 'four', 'sequences:', 'the', 'reference', 'sequence,', 'its', 'reverse', 'complement,', 'the', 'variant', 'sequence,', 'and', 'its', 'reverse', 'complement.', 'For', 'each', 'of', 'these', 'four', 'sequences,', 'we', 'focused', 'on', 'the', 'narrower', 'loci', 'surrounding', 'the', 'variant', 'site', 'and', 'calculated', 'average', 'embeddings', 'across', 'different', 'window', 'sizes', '(ranging', 'from', '16', 'to', '8,192', 'nucleotides', 'in', 'powers', 'of', '2).', 'We', 'then', 'concatenatedthevectorsfromallfoursequencesintoasingle32,768-dimensionalfeaturevectorforeachSNV.', 'These', 'feature', 'vectors', 'were', 'used', 'to', 'train', 'a', 'classification', 'model', 'using', 'the', 'same', 'architecture', 'and', 'parameters', 'as', 'the', 'model', 'described', 'previously.', 'Among', 'the', 'different', 'window', 'sizes', 'for', 'averaging,', 'we', 'found', 'that', 'using', 'a', '128nt', 'window', 'produced', 'the', 'best', 'results,', 'achieving', 'an', 'AUROC', 'of', '0.95', 'on', 'the', 'test', 'set.', 'This', 'is', 'the', 'model', 'we', 'use', 'for', 'comparison', 'with', 'zero-shot', 'methods', 'throughout', 'our', 'figures.', '4.4.', 'Mechanistic', 'interpretability', 'with', 'sparse', 'autoencoders', '4.4.1.', 'SAE', 'training', 'and', 'dataset', 'composition', 'WetrainedaBatchTopKsparseautoencoder(Bussmannetal.,', '2024),avariantoftheTopKsparseautoencoder', '(Makhzani', 'and', 'Frey,', '2014;Gao', 'et', 'al.,', '2024a)', 'on', 'activations', 'from', 'the', 'Evo', '2', 'residual', 'stream', 'following', 'layer', '26', '(a', 'Hyena-MR', 'block)', 'for', 'an', 'intermediate', 'checkpoint', 'of', 'the', '7B', 'model', 'that', 'was', 'context-extended', 'to', '262,144', 'tokens.', 'Sparse', 'autoencoders', 'take', 'as', 'input', 'model', 'activations', '𝑥', 'and', 'autoencode', 'them', 'into', 'a', 'sparse', 'feature', 'vector', '𝑓', ',', 'before', 'predicting', 'a', 'reconstruction', 'of', 'the', 'inputs', 'ˆ', '𝑥', '.', 'The', 'conventional', 'SAE', 'architecture', '(which', 'we', 'also', 'make', 'use', 'of', 'here)', 'is', 'a', 'very', 'wide', 'MLP', 'with', 'one', 'hidden', 'layer:', '𝑓', '=', '𝜎', '(', '𝑊𝑒𝑥', '+', '𝑏𝑒', ')', 'ˆ', '𝑥', '=', '𝑊𝑑𝑓', '+', '𝑏𝑑', '.', 'The', 'nonlinearity', '𝜎', '(·)that', 'we', 'use', 'is', 'the', 'Batch-TopK', 'activation', 'function.', 'The', 'Batch-TopK', 'activation', 'function', 'is', 'a', 'version', 'of', 'the', 'TopK', 'activation', 'function,', 'which', 'zeros', 'out', 'all', 'but', 'the', '𝑘', 'largest', 'elements', 'of', 'a', 'vector.', 'The', 'BatchTopK', 'activation', 'function', 'with', 'an', 'equivalent', 'value', 'of', '𝑘', 'and', 'a', 'batch', 'of', 'size', '𝐵', 'zeros', 'out', 'all', 'but', 'the', '𝑘𝐵', 'largest', 'elements', 'of', 'the', 'input', 'batch.', 'This', 'allows', 'the', 'SAE', 'to', 'flexibly', 'allocate', 'capacity', 'to', 'higher-complexity', 'inputs.', 'Evo', '2', 'activations', 'have', 'dimensionality', '𝑑', 'model', '=4,096and', 'our', 'SAE', 'has', 'feature', 'dimensionality', '𝑑', 'feature', '=', '8×4,096=32,768.', 'We', 'used', '𝑘', '=64for', 'our', 'SAE', 'training.', 'Batch-TopK', 'SAEs', 'are', 'trained', 'with', 'a', 'loss', 'L=Lrecon+', '𝛼', 'Lauxthat', 'combines', 'a', 'reconstruction', 'loss', 'Lreconand', 'auxiliary', 'lossLaux.', 'The', 'reconstruction', 'loss', 'is', 'simply', 'the', 'mean', 'squared', 'reconstruction', 'error:', 'Lrecon=∥', '𝑥', '−ˆ', '𝑥', '∥2', '2,', 'and', 'the', 'auxiliary', 'loss', 'Lauxpredicts', 'the', 'residual', '𝜀', '=', '𝑥', '−ˆ', '𝑥', 'using', 'only', '“dead', 'features”', '(see', 'Gao', 'et', 'al.', '(2024a)', 'andBussmann', 'et', 'al.', '(2024)', 'for', 'details).', 'A', 'dead', 'feature', 'is', 'a', 'feature', '𝑓𝑖', 'which', 'has', 'not', 'fired', '(i.e.,', '𝑓𝑖', '=0)', 'for', '31.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'some', 'large', 'number', 'of', 'inputs', 'during', 'training.', 'We', 'call', 'a', 'feature', 'dead', 'if', 'it', 'has', 'not', 'fired', 'for', '10', 'million', 'training', 'inputs.', 'Our', 'main', 'SAE', '(which', 'we', 'refer', 'to', 'as', 'the', 'mixed-data', 'SAE)', 'was', 'trained', 'on', 'a', 'dataset', 'of', 'prokaryotic', 'and', 'eukaryotic', 'genomes,', 'representing', 'a', 'small', 'subset', 'of', 'OpenGenome2.', 'For', 'prokaryotes,', 'genomes', 'were', 'collected', 'from', 'GTDB', 'release', '220.0,', 'filtering', 'for', 'genomes', 'annotated', 'as', 'GTDB', 'and', 'NCBI', 'representative', 'genomes,', 'and', 'assembly', 'level', 'annotated', 'as', '“complete”,', 'totaling', '2752', 'genomes', 'and', '10.97', 'billion', 'base', 'pairs.', 'For', 'eukaryotic', 'genomes,16representativespecieswereselected(see', 'Section4.3.3),andonlyregionswithhighgenecontent', '(genic', 'regions,', 'see', 'Section4.2.2)', 'were', 'used', 'for', 'SAE', 'training,', 'totaling', '4.91', 'billion', 'base', 'pairs.', 'We', 'subsampled', 'this', 'dataset', 'to', '1', 'billion', 'activations', 'from', 'sequence', 'chunks', 'of', 'length', '16,384', 'to', 'provide', 'SAE', 'training', 'data.', 'These', 'activations', 'were', 'then', 'globally', 'shuffled', 'so', 'that', 'activations', 'from', 'the', 'same', 'input', 'sequence', 'were', 'unlikely', 'to', 'occur', 'in', 'the', 'same', 'SAE', 'training', 'batch.', 'We', 'trained', 'the', 'SAE', 'using', 'the', 'Adam', 'optimizer', 'with', 'a', 'learning', 'rate', 'of', '5×10−5,', 'default', 'values', 'of', '𝛽', '1and', '𝛽', '2,', 'and', 'a', 'batch', 'size', 'of', '16,384', 'for', 'a', 'single', 'epoch.', 'We', 'used', 'a', 'trapezoidal', 'learning', 'rate', 'schedule,', 'ramping', 'up', 'from', 'zero', 'for', 'the', 'first', '5%', 'of', 'training', 'and', 'ramping', 'down', 'to', 'zero', 'for', 'the', 'last', '5%.', 'We', 'also', 'trained', 'an', 'SAE', 'solely', 'on', 'eukaryotic', 'data', '(which', 'we', 'refer', 'to', 'as', 'the', 'eukaryotic', 'data', 'SAE).', 'The', 'eukaryotic', 'data', 'SAE', 'was', 'identically', 'trained', 'to', 'the', 'mixed-data', 'SAE,', 'except', 'that', 'instead', 'of', 'subsampling', '1B', 'tokens', 'from', 'the', 'combined', 'eukaryotic', 'and', 'prokaryotic', 'datasets,', 'we', 'subsampled', 'only', 'from', 'the', 'eukaryotic', 'dataset', 'described', 'above.', '4.4.2.', 'SAE', 'metrics', 'and', 'feature', 'embedding', 'calculation', 'To', 'compute', 'some', 'basic', 'statistics', 'for', 'the', 'trained', 'mixed-data', 'SAE,', 'activations', 'were', 'computed', 'for', 'all', 'features', 'across', 'the', 'E.', 'coliK12', 'MG1655', 'genome', '(NCBI', 'reference', 'sequence', 'NC_000913.3)', 'and', 'a', 'length-matched', 'seg-', 'ment', 'of', 'human', 'chromosome', '17', '(NCBI', 'reference', 'sequence', 'NC_000017.11,', 'bases', '40,019,967-44,661,618)', 'in', '50', 'kb', 'non-overlapping', 'sequence', 'chunks.', 'Activation', 'density', 'for', 'each', 'feature', 'was', 'then', 'computed', 'as', 'the', 'fraction', 'of', 'non-zero', 'activations', 'and', 'the', 'mean', 'non-zero', 'activation', 'computed', 'as', 'expected', 'across', 'all', 'sequence', 'chunks', 'from', 'the', 'relevant', 'genome', 'for', 'both', 'prokaryotes', 'and', 'eukaryotes.', 'To', 'visualize', 'the', 'features', 'in', 'an', 'embed-', 'ding,', 'the(4096×32768)weights', 'matrix', 'was', 'column-normalized', 'and', 'then', 'embedded', 'using', 'UMAP', '(McInnes', 'et', 'al.,2018)', 'with', '2', 'components', 'and', 'random', 'seed', '1', 'and', 'visualized', 'by', 'coloring', 'each', 'point', 'by', 'the', 'difference', 'in', 'prokaryotic', 'and', 'eukaryotic', 'activation', 'density', 'for', 'each', 'feature.', '4.4.3.', 'Prophage', 'feature', 'To', 'identify', 'a', 'prophage-associated', 'feature,', 'we', 'used', 'contrastive', 'feature', 'search', 'on', '100', 'kb', 'sequences', 'that', 'are', 'centered', 'on', 'geNomad-annotated', '(Camargo', 'et', 'al.,', '2024)', 'phage', 'regions', 'and', 'include', 'flanking', 'bacterial', 'regions.', 'These', 'sequences', 'were', 'from', '100', 'randomly', 'selected', 'genomes', 'from', 'GTDB.', 'The', 'feature', 'with', 'the', 'highest', 'mean', 'differential', 'activation', '(f/19746)', 'was', 'selected.', 'To', 'evaluate', 'the', 'predictive', 'value', 'of', 'this', 'feature,', 'we', 'analyzed', 'its', 'mean', 'activation', 'values', 'in', 'prophage', 'regions.', 'We', 'then', 'compared', 'these', 'values', 'against', 'length-matched', 'bacterial', '(non-phage)', 'sequences', 'from', 'the', 'same', 'genome,', 'sampled', 'without', 'replacement.', 'To', 'analyze', 'this', 'feature', 'at', 'the', 'genome', 'scale,', 'we', 'computed', 'feature', 'activations', 'on', '50', 'kb', 'non-overlapping', 'chunks', 'of', 'the', 'E.', 'coliK12', 'MG1655', 'genome,', 'and', 'compared', 'them', 'with', 'RefSeq-annotated', 'phage', 'regions.', 'In', 'the', 'genome-scale', 'plot', 'in', 'Figure4B,', 'we', 'de-noise', 'feature', 'activations', 'by', 'setting', 'a', 'position’s', 'activation', 'to', '0', 'if', 'it', 'does', 'not', 'have', 'a', 'neighboring', 'position', 'with', 'a', 'nonzero', 'activation.', 'From', 'the', 'dataset', 'of', '100', 'randomly', 'selected', 'GTDB', 'genomes,', 'we', 'selected', '3', 'loci', 'with', 'the', 'highest', 'f/19746', 'activation', 'values', 'outside', 'of', 'phage-annotated', 'regions', 'for', 'visualization', 'in', 'FigureS6D.', 'As', 'feature', 'f/19746', 'also', 'activated', 'on', 'the', 'region', 'downstream', 'of', 'the', 'last', 'CRISPR', 'direct', 'repeat', 'in', 'E.', 'coli,', 'we', 'sought', 'to', 'determine', 'whether', 'Evo', '2', 'is', 'learning', 'to', 'associate', 'sequences', 'downstream', 'of', 'CRISPR', 'direct', 're-', 'peats', '(like', 'CRISPR', 'spacers)', 'with', 'phage', 'sequences', 'or', 'directly', 'memorizing', 'phage', 'sequences.', 'We', 'investigated', 'this', 'by', 'performing', 'ablations', 'on', 'the', 'sequence.', 'Using', 'the', 'same', 'CRISPR', 'locus', 'displayed', 'in', 'Figure4B,', 'we', 'first', 'computed', 'feature', 'activations', 'on', 'a', 'synthetic', 'sequence', 'where', 'all', 'spacer', 'sequences', 'in', 'the', 'CRISPR', 'array', 'were', 'independently', 'scrambled.', 'Observing', 'that', 'this', 'did', 'not', 'result', 'in', 'a', 'change', 'in', 'the', 'feature', 'activation', 'pattern,', 'we', 'then', 'computed', 'feature', 'activations', 'on', 'a', 'synthetic', 'sequence', 'in', 'which', 'all', 'the', 'CRISPR', 'direct', 'repeats', 'were', 'replaced', 'with', 'a', 'constant', 'scrambled', 'sequence,', 'while', 'keeping', 'the', 'spacer', 'sequences', 'unchanged', 'from', 'the', 'nat-', 'ural', 'sequence.', 'Lastly,', 'we', 'repeated', 'the', 'previous', 'test', 'but', 'replaced', 'CRISPR', 'direct', 'repeats', 'with', 'nonconstant,', 'scrambled', 'sequences.', '32.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', '4.4.4.', 'E.', 'coli', 'genomic', 'loci', 'features', 'Features', 'reflecting', 'genome', 'organization', 'were', 'identified', 'using', 'a', 'combination', 'of', 'contrastive', 'feature', 'search', 'and', 'manual', 'examination', 'of', 'features', 'with', 'large', 'total', 'activations', 'over', 'sequence', 'chunks', 'of', 'the', 'E.', 'coliK12', 'MG1655', 'genome', '(NCBI', 'reference', 'sequence', 'NC_000913.3),', 'as', 'annotated', 'by', 'RefSeq.', 'Feature', 'activations', 'for', 'the', '100', 'kb', 'segment', 'displayed', 'in', 'the', 'figures', 'were', 'computed', 'over', 'the', 'full', '100', 'kb', 'segment', 'as', 'one', 'batch.', 'To', 'quantify', 'mean', 'activations', 'over', 'annotations,', 'activations', 'were', 'computed', 'over', 'non-overlapping', '50', 'kb', 'chunksofthe', 'E.', 'coliK12MG1655genome.', 'EachnucleotideinthegenomewasgroupedintoORF,tRNA,rRNA,', 'or', 'intergenic', 'annotations', 'based', 'on', 'existing', 'RefSeq', 'annotations,', 'with', 'the', 'intergenic', 'annotations', 'including', 'all', 'sequences', 'that', 'were', 'not', 'categorized', 'as', 'ORF,', 'tRNA,', 'or', 'rRNA.', 'ORF', 'annotations', 'were', 'further', 'categorized', 'into', '(+)', 'ORF', 'and', '(-)', 'ORF', 'depending', 'on', 'their', 'directionality.', 'For', 'each', 'annotation,', 'mean', 'activation', 'for', 'each', 'feature', 'was', 'computed', 'by', 'extracting', 'and', 'averaging', 'the', 'activations', 'across', 'all', 'nucleotides', 'within', 'the', 'annotation.', '4.4.5.', 'Protein', 'secondary', 'structure', 'features', 'We', 'identified', '𝛼', '-helix', 'and', '𝛽', '-sheet', 'associated', 'features', 'using', 'contrastive', 'feature', 'search', 'on', 'all', 'coding', 'sequences', 'in', 'the', 'E.', 'coliK12', 'MG1655', 'genome.', 'Secondary', 'structure', 'annotations', 'were', 'obtained', 'using', 'the', 'DSSP', 'algo-', 'rithm', '(Kabsch', 'and', 'Sander,', '1983;Kunzmann', 'et', 'al.,', '2023)', 'on', 'structures', 'from', 'the', 'AlphaFold', 'Protein', 'Structure', 'Database', '(Tunyasuvunakool', 'et', 'al.,', '2021).', 'For', 'each', 'feature,', 'we', 'computed', 'the', 'Pearson', 'correlation', 'between', 'its', 'activation', 'pattern', 'on', 'a', 'coding', 'sequence', 'and', 'the', 'secondary', 'structure', 'annotations', 'of', 'the', 'encoded', 'protein,', 'for', 'all', 'coding', 'sequences.', 'The', 'features', 'with', 'the', 'highest', 'mean', 'Pearson', 'correlation', 'with', '𝛼', '-helix', 'regions', '(f/28741)', 'and', '𝛽', '-sheet', 'regions', '(f/22326)', 'were', 'selected.', 'Structures', 'of', 'EF-Tu', 'in', 'complex', 'with', 'thrT', 'tRNA,', 'and', 'of', 'RpoB', 'and', 'RpoC', 'in', 'complex,', 'were', 'obtained', 'using', 'AlphaFold3(Abramsonetal.,', '2024)throughtheAlphaFoldserver.', 'Toprojectthefeaturesontothestructures,', 'we', 'first', 'preprocessed', 'the', 'feature', 'activation', 'values.', 'Except', 'for', 'thrT', 'tRNA,', 'we', 'first', 'mean', 'collapsed', 'feature', 'activations', 'per', 'codon,', 'as', 'feature', 'activations', 'were', 'computed', 'at', 'the', 'genome', 'level.', 'Feature', 'activations', 'were', 'then', 'smoothed', 'using', 'a', 'Gaussian', 'kernel', 'with', 'a', 'window', 'size', 'of', '10.', 'We', 'then', 'overlaid', 'the', 'smoothed', 'feature', 'activations', 'on', 'the', 'structures,', 'using', 'linear', 'interpolation', 'coloring', 'and', 'clipping', 'values', 'at', 'a', 'maximum', 'threshold', 'of', '0.2,', 'visualized', 'using', 'ChimeraX', '(Meng', 'et', 'al.,', '2023).', '4.4.6.', 'Frameshift', 'and', 'premature', 'stop', 'feature', 'Using', 'the', 'same', 'set', 'of', 'artificially', 'mutated', 'coding', 'sequences', 'generated', 'previously', 'for', 'the', 'human', 'genome,', 'contrastivefeaturesearchwasusedwiththeeukaryoticdataSAEtoidentifyfeaturesthatseemedtospecifically', 'correspond', 'with', 'frameshift', 'and', 'premature', 'stop', 'codon', 'mutations,', 'but', 'not', 'synonymous', 'or', 'nonsynonymous', 'substitutions.', 'A', 'subset', 'of', '100', 'loci', 'was', 'first', 'used', 'to', 'calculate', 'average', 'feature', 'activations', 'across', 'all', 'mutation', 'types', 'in', '8192', 'bp', 'windows.', 'The', 'difference', 'in', 'mean', 'feature', 'activations', 'between', 'the', 'mutated', 'and', 'reference', 'sequencewasusedtoprioritizefeatures.', 'Top20featuresforeachmutationtypewereidentified.', 'Featuresthat', 'were', 'among', 'the', 'top', '20', 'predictors', 'for', 'both', 'frameshift', 'and', 'premature', 'stop', 'codon', 'mutations', 'were', 'identified.', 'Features', 'that', 'were', 'also', 'in', 'the', 'top', '20', 'for', 'synonymous', 'or', 'nonsynonymous', 'substitutions', 'were', 'then', 'excluded', 'from', 'this', 'subset.', 'This', 'resulted', 'in', '3', 'remaining', 'features:', 'f/24278,', 'f/29870,', 'and', 'f/18585.', 'f/24278', 'was', 'then', 'selected', 'for', 'further', 'analysis.', 'A', 'separate', 'subset', 'of', '100', 'sequences,', 'each', 'of', 'length', '8192', 'bp,', 'was', 'used', 'to', 'analyze', '24,278', 'feature', 'activations', 'on', 'a', 'per-nucleotide,', 'and', 'this', 'subset', 'was', 'used', 'to', 'determine', 'the', 'average', 'feature', 'activation', 'pattern', 'near', 'the', 'mutation', 'site.', 'A', 'separate', 'subset', 'of', '500', 'sequences', 'was', 'then', 'used', 'to', 'estimate', 'the', 'precision,', 'recall,', 'and', 'the', 'F1', 'score', 'of', 'the', 'feature.', 'For', 'calculating', 'these', 'metrics,', 'any', 'non-zero', 'activation', 'of', 'the', 'feature', 'within', '100', 'bp', 'after', 'the', 'mutation', 'position', 'was', 'considered', 'a', 'true', 'positive.', '4.4.7.', 'Transcription', 'factor', 'motif', 'features', 'From', 'the', 'GRCh38', 'human', 'reference', 'genome', '(Schneider', 'et', 'al.,', '2017),', 'a', 'random', 'sample', 'of', '1,000', 'promoter', 'sequences,', 'defined', 'as', '1', 'kb', 'upstream', 'of', 'a', 'transcription', 'start', 'site,', 'was', 'selected', 'and', 'passed', 'through', 'the', 'model,', 'in', 'batches', 'of', '100', 'sequences,', 'to', 'extract', 'the', 'SAE', 'feature', 'activations.', 'All', 'feature', 'activations', 'above', 'the', 'sparsity', 'threshold', 'of', '1×10−4were', 'stored', 'in', 'sparse', 'matrices', 'from', 'these', 'activations.', 'Following', 'this', 'selection,', '31', 'bp', 'windowscenteredoneachpositionwithafeatureactivationgreaterthanthesparsitythresholdwereextracted.', 'To', 'ensure', 'robust', 'motif', 'detection,', 'a', 'selection', 'pipeline', 'for', 'good', 'features', 'was', 'established.', 'First,', 'features', '33.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', 'were', 'required', 'to', 'have', 'activations', 'across', 'at', 'least', '50', 'promoter', 'sequences', 'to', 'be', 'considered', 'for', 'further', 'analysis.', 'For', 'each', 'feature', 'activation', 'window,', 'sequence', 'complexity', 'was', 'assessed', 'using', 'Shannon', 'entropy,', 'calculated', 'as', '𝐻', '=−Í', '𝜋', 'log2(', '𝜋', ')where', '𝜋', 'represents', 'the', 'frequency', 'of', 'each', 'nucleotide', 'in', 'the', 'sequence.', 'To', 'ensure', 'high-', 'quality', 'motif', 'detection,', 'sequences', 'below', 'the', '25th', 'percentile', 'of', 'complexity', 'scores', 'were', 'filtered', 'out.', 'Position', 'Weight', 'Matrices', '(PWMs)', 'were', 'constructed', 'from', 'the', 'remaining', 'sequences,', 'and', 'information', 'content', '(IC)', 'was', 'calculated', 'for', 'each', 'position', 'as', '2−', '𝐻', 'of', 'the', 'nucleotide', 'frequencies', 'in', 'the', 'PWM.', 'The', 'motif', 'scoring', 'system', 'incorporated', 'multiple', 'metrics:', 'maximum', 'IC,', 'IC', 'variance', '(to', 'identify', 'sharp', 'conservation', 'peaks),', 'peak', 'width', '(number', 'of', 'positions', 'with', 'IC', '>', '0.5),', 'and', 'peak', 'spacing.', 'Penalties', 'were', 'applied', 'for', 'deviating', 'from', 'expected', 'transcription', 'factor', 'binding', 'site', 'characteristics:', 'a', 'width', 'penalty', 'for', 'diverging', 'from', 'the', 'optimal', '6-8', 'bp', 'width,', 'and', 'a', 'peak', 'penalty', 'for', 'having', 'significantly', 'more', 'or', 'fewer', 'than', '1-2', 'distinct', 'peaks.', 'The', 'final', 'motif', 'score', 'was', 'calculated', 'as', '(maximum', 'IC', '*', '2', '+', 'IC', 'variance)', '*', '(1', '/', '(1', '+', 'width', 'penalty', '+', 'peak', 'penalty)),', 'with', 'features', 'requiring', 'a', 'maximum', 'IC', '>', '0.3', 'to', 'be', 'considered', 'valid', 'motifs.', 'After', 'this', 'filtering,', 'motifs', 'were', 'scored', 'based', 'on', 'the', 'maximum', 'information', 'content,', 'number', 'of', 'high-information', 'positions,', 'information', 'content', 'variance,', 'and', 'sequence', 'complexity.', 'For', 'some', 'motifs,', 'an', 'additional', 'scoring', 'metric,', 'the', 'number', 'of', 'zeros', 'appearing', 'in', 'the', 'count', 'matrices,', 'was', 'also', 'incorporated', 'into', 'the', 'scoring.', 'Sequence', 'logos', 'were', 'generated', 'using', 'the', 'Logomaker', 'package(TareenandKinney,', '2019)forvisualinspection,', 'andtheJASPARcountmatriceswerepassedthrough', 'the', 'MEME', 'suite', 'TOMTOM', 'Motif', 'Comparison', 'Tool', '(v5.5.7)', '(Gupta', 'et', 'al.,', '2007)', 'with', 'the', '“Human', 'and', 'Mouse', '(HOCOMOCO', 'V12', 'CORE)”', 'dataset', '(Vorontsov', 'et', 'al.,', '2023)', 'to', 'match', 'the', 'motifs', 'to', 'known', 'transcription', 'factor', 'binding', 'motifs.', '4.4.8.', 'Exon-intron', 'features', 'SAE', 'features', 'associated', 'with', 'eukaryotic', 'coding', 'sequences,', 'introns,', 'and', 'exon-intron', 'boundaries', 'were', 'found', 'through', 'contrastive', 'feature', 'search', 'on', 'the', 'annotated', 'sequence', 'of', 'chromosome', '1', 'of', 'the', 'GRCh38', 'human', 'ref-', 'erence', 'genome', '(Schneider', 'et', 'al.,', '2017).', '50', 'exon-rich', 'segments', 'of', 'length', '8,192', 'nt', 'were', 'sampled', 'from', 'this', 'reference', 'sequence,', 'and', 'feature', 'activations', 'were', 'collected', 'from', 'each', 'segment.', 'Then,', 'we', 'searched', 'for', 'features', 'with', 'the', 'top-20', 'highest', 'values', 'of', 'the', 'weighted', 'sum', '∑', '︁', '𝑖𝑓𝑖', '(4', '𝑚𝑖', '−3),', 'where', '𝑓𝑖', 'is', 'the', 'activation', 'at', 'base', '𝑖', ',', 'and', '𝑚𝑖', 'is', '1', 'if', 'base', '𝑖', 'is', 'annotated', 'as', 'the', 'given', 'genomic', 'component', '(CDS,', 'intron,', 'exon', 'start,', 'exon', 'end),', 'and', '0', 'if', 'not.', 'For', 'features', 'associated', 'with', 'exon', 'starts', 'and', 'ends,', 'the', 'first', '50', 'bases', 'and', 'the', 'last', '50', 'bases', 'of', 'each', 'exon', 'were', 'used', 'as', 'the', 'loci', 'where', '𝑚𝑖', 'is', '1,', 'respectively.', 'The', 'features', 'that', 'are', 'presented', 'most', 'frequently', 'in', 'these', '50', 'segmentswerevisuallyinspectedtodeterminethefeaturesthatactivatethemostconsistentlyattherespective', 'loci,', 'and', 'a', 'representative', 'feature', 'was', 'chosen', 'for', 'CDS,', 'introns,', 'exon', 'starts,', 'and', 'exon', 'ends.', 'To', 'calculate', 'the', 'F1,', 'precision,', 'and', 'recall', 'scores', 'for', 'each', 'feature,', 'we', 'sampled', '1,000', 'genes', 'with', '5', 'or', 'more', 'exons', 'from', 'the', 'human', 'genome,', 'and', 'counted', 'the', 'bases', 'where', 'the', 'features', 'have', 'a', 'nonzero', 'activation', 'on', 'or', 'off', 'the', 'genomic', 'regions', 'corresponding', 'to', 'each', 'feature.', 'The', 'reference', 'genome', 'annotations', 'for', 'CDS', 'and', 'introns', 'were', 'considered', 'to', 'be', 'ground', 'truth', 'in', 'calculating', 'the', 'numbers', 'of', 'true/false', 'positives/negatives.', 'For', 'the', 'exon', 'start', 'feature', '(f/1050),', 'we', 'considered', 'the', 'first', '25', 'bases', 'of', 'each', 'exon', 'following', 'an', 'intron', 'to', 'be', 'the', 'ground', 'truth,', 'in', 'consideration', 'of', 'the', 'firing', 'patterns', 'of', 'the', 'feature.', 'For', 'the', 'exon', 'end', 'feature', '(f/25666),', 'we', 'considered', 'the', 'last', 'one', 'base', 'of', 'each', 'exon', 'followed', 'by', 'an', 'intron', 'to', 'be', 'the', 'ground', 'truth', 'label.', 'To', 'calculate', 'the', 'mean', 'activations', 'of', 'features', 'for', 'each', 'type', 'of', 'genomic', 'loci,', 'we', 'used', 'the', 'same', 'set', 'of', '1,000', 'genes', 'and', 'calculated', 'the', 'average', 'activations', 'of', 'each', 'feature', 'for', 'each', 'individual', 'genomic', 'locus', 'identified', 'by', 'the', 'ground', 'truth', 'labels', '–', 'a', 'single', 'exon,', 'a', 'single', 'intron,', 'first', '25', 'bases', 'of', 'a', 'single', 'exon,', 'and', 'the', 'last', 'base', 'of', 'a', 'single', 'exon.', 'The', 'activations', 'for', 'the', 'same', 'set', 'of', 'features', 'were', 'collected', 'for', 'the', 'PDK3gene', 'loci', 'of', 'the', 'woolly', 'mammoth', 'genome', '(Sandoval-Velasco', 'et', 'al.,', '2024).', 'The', 'exon', 'coordinates', 'of', 'the', 'mammoth', 'genome', 'were', 'derived', 'from', 'homologs', 'to', 'the', 'Loxodonta', 'africana', 'genome.', 'Note', 'that', 'while', 'the', 'Loxodonta', 'africana', 'genomic', 'sequence', 'was', 'part', 'of', 'the', 'training', 'corpus', 'for', 'Evo', '2,', 'it', 'was', 'not', 'part', 'of', 'the', 'training', 'data', 'used', 'to', 'collect', 'activations', 'for', 'the', 'SAE.', '34.', 'CC-BY-ND', '4.0', 'International', 'license', 'perpetuity.', 'It', 'is', 'made', 'available', 'under', 'apreprint', '(which', 'was', 'not', 'certified', 'by', 'peer', 'review)', 'is', 'the', 'author/funder,', 'who', 'has', 'granted', 'bioRxiv', 'a', 'license', 'to', 'display', 'the', 'preprint', 'in', 'The', 'copyright', 'holder', 'for', 'this', 'this', 'version', 'posted', 'February', '21,', '2025.', ';', 'https://doi.org/10.1101/2025.02.18.638918doi:', 'bioRxiv', 'preprint', '4.4.9.', 'SAE', 'feature', 'visualization', 'web', 'viewer', 'We', 'manually', 'curated', '104', 'prokaryotic', 'genomes', 'of', 'microbiological,', 'medical,', 'or', 'agricultural', 'relevance', 'from', 'NCBI.', 'These', 'genomes', 'were', 'annotated', 'using', 'the', 'Bakta', 'v1.10.3', 'pipeline', '(Schwengers', 'et', 'al.,', '2021),', 'putative', 'prohage', 'regions', 'were', 'annotated', 'using', 'geNomad', '(Camargo', 'et', 'al.,', '2024),', 'and', 'secondary', 'structure', 'annotations', 'wereobtainedusingtheDSSPalgorithm(KabschandSander,', '1983;Kunzmannetal.,', '2023)onstructuresfrom', 'the', 'AlphaFold', 'Protein', 'Structure', 'Database', '(Tunyasuvunakool', 'et', 'al.,', '2021).', 'Activations', 'were', 'computed', 'for', 'all', 'features', 'without', 'using', 'the', 'Batch-TopK', 'activation', 'function,', 'and', 'the', 'top', '50', 'largest', 'activations', 'per', 'token', 'were', 'retained.', 'Building', 'on', 'igv.js', '(Robinson', 'et', 'al.,', '2022),', 'features', 'identified', 'as', 'mapping', 'to', 'prokaryotic', 'concepts', 'are', 'plotted', 'and', 'interactively', 'displayed', 'at', 'https://arcinstitute.org/tools/evo/evo-mech-interp.', '4.5.', 'Unconstrained', 'generation', 'with', 'Evo', '2', '4.5.1.', 'Gene', 'completion', 'DNAsequenceswerecollectedaroundgenesfrom', 'Haloferax', 'volcanii,', 'Escherichia', 'coli,', 'Saccharomyces', 'cerevisiae,', 'Chlamydomonas', 'reinhardtii,', 'Arabidopsis', 'thaliana,', 'and', 'Homo', 'sapiens,', 'covering', 'archaeal,', 'prokaryotic,', 'and', 'eu-', 'karyotic', 'species.', 'For', 'each', 'gene,', 'a', 'prompt', 'of', '1,000', 'base', 'pairs', 'upstream', 'of', 'the', 'gene', 'and', 'the', 'first', '500', 'bp', '(Haloferax', 'volcanii,', 'Escherichia', 'coli,', 'Saccharomyces', 'cerevisiae)', 'or', '1000', 'bp', '(Chlamydomonas', 'reinhardtii,', 'Ara-', 'bidopsis', 'thaliana,', 'and', 'Homo', 'sapiens)', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzw7JBH0F10o",
        "outputId": "04bb47df-f63d-48d7-b40f-ab4fdb6b17dd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accessibility access\n",
            "in in\n",
            "some some\n",
            "genomic genom\n",
            "regions region\n",
            "and and\n",
            "minimize minim\n",
            "accessibility access\n",
            "in in\n",
            "other other\n",
            "regions. regions.\n",
            "AlthoughEvo2hasnoexplicitmechanismforconditioningitsgenerationsbasedonepigeneticstate,several althoughevo2hasnoexplicitmechanismforconditioningitsgenerationsbasedonepigeneticstate,sever\n",
            "models model\n",
            "such such\n",
            "as as\n",
            "Enformer enform\n",
            "(Avsec (avsec\n",
            "et et\n",
            "al., al.,\n",
            "2021) 2021)\n",
            "and and\n",
            "Borzoi borzoi\n",
            "(Linder (linder\n",
            "et et\n",
            "al., al.,\n",
            "2025) 2025)\n",
            "demonstrate demonstr\n",
            "accurate, accurate,\n",
            "held-out held-out\n",
            "performance perform\n",
            "in in\n",
            "predicting predict\n",
            "chromatin chromatin\n",
            "accessibility access\n",
            "profiles profil\n",
            "from from\n",
            "DNA dna\n",
            "sequence sequenc\n",
            "across across\n",
            "cell cell\n",
            "types type\n",
            "from from\n",
            "human human\n",
            "and and\n",
            "mouse. mouse.\n",
            "However, however,\n",
            "models model\n",
            "like like\n",
            "Enformer enform\n",
            "and and\n",
            "Borzoi borzoi\n",
            "are are\n",
            "not not\n",
            "trained train\n",
            "as as\n",
            "generative gener\n",
            "models model\n",
            "and and\n",
            "assume assum\n",
            "that that\n",
            "their their\n",
            "sequence sequenc\n",
            "inputs input\n",
            "come come\n",
            "from from\n",
            "natural natur\n",
            "genomes. genomes.\n",
            "Evo evo\n",
            "2 2\n",
            "captures captur\n",
            "complex complex\n",
            "rules rule\n",
            "across across\n",
            "mammalian mammalian\n",
            "genomes genom\n",
            "(Figures (figur\n",
            "2and3) 2and3)\n",
            "and and\n",
            "is is\n",
            "a a\n",
            "powerful power\n",
            "generative gener\n",
            "model model\n",
            "that that\n",
            "can can\n",
            "be be\n",
            "used use\n",
            "to to\n",
            "propose propos\n",
            "diverse divers\n",
            "sequences sequenc\n",
            "while while\n",
            "retaining retain\n",
            "biological biolog\n",
            "“naturalness” “naturalness”\n",
            "(Figure (figur\n",
            "5). 5).\n",
            "To to\n",
            "achieve achiev\n",
            "controllable control\n"
          ]
        }
      ],
      "source": [
        "#implementacion de Algoritmo de porter\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "p_stemmer = PorterStemmer()\n",
        "words = tokenized_pdf\n",
        "#Visualizar las primeras 100 tokens\n",
        "for word in words[8000:8100]:\n",
        "  print(word+\" \"+p_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las Reglas aplicadas en el algoritmo de porter son:\n",
        "\n",
        "- Regla 1:\n",
        "\n",
        "Remover sufijos simples, como los de los plurales y verbos irregulares en pasado\n",
        "\n",
        "(\"s\", \"es\", \"ed\", \"ing\").\n",
        "\n",
        "\n",
        "- Regla 2:\n",
        "\n",
        "Remover sufijos complejos como -ational e -ization\n",
        "\n",
        "- Regla 3:\n",
        "\n",
        "Sufijos comunes son removidos como \"er\", \"ly\", \"ment\". \"ness\"\n",
        "\n",
        "- Regla 4:\n",
        "\n",
        "Sufijos comunes son removidos como “al”, “ance”, “ence”, etc.\n",
        "\n",
        "- Regla 5\n",
        "\n",
        "Reglas adicionales como remocion del la \"e\"\n",
        "\n"
      ],
      "metadata": {
        "id": "cuzomtQV3-OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lemmatizador y Stemming para el idioma Español\n",
        "\n",
        "- Construir un lematizador y stemming para español con al menos 10 reglas. Aplicarlo al conjunto de twitter."
      ],
      "metadata": {
        "id": "8_Brxu5M8NRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def lematizar_y_stem(normalized_tokens):\n",
        "    \"\"\"\n",
        "    Función que recibe una lista de tokens normalizados en español\n",
        "    y devuelve una lista de diccionarios con el token original y su stem.\n",
        "    \"\"\"\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    #Diccionario de algunos lemas irregulares\n",
        "    lemas_irregulares = {\n",
        "        \"fui\": \"ir\",\n",
        "        \"fuiste\": \"ir\",\n",
        "        \"fue\": \"ir\",\n",
        "        \"fueron\": \"ir\",\n",
        "        \"soy\": \"ser\",\n",
        "        \"eres\": \"ser\",\n",
        "        \"es\": \"ser\",\n",
        "        \"somos\": \"ser\",\n",
        "        \"son\": \"ser\",\n",
        "        \"quiero\": \"querer\",\n",
        "        \"quieres\": \"querer\",\n",
        "        \"quiere\": \"querer\",\n",
        "        \"quieren\": \"querer\"\n",
        "    }\n",
        "\n",
        "    for token in normalized_tokens:\n",
        "        # Skip tokens starting with '#' or '@'\n",
        "        if token.startswith('#') or token.startswith('@'):\n",
        "            resultados.append({\n",
        "                token # Return the token as is\n",
        "            })\n",
        "            continue # Move to the next token\n",
        "\n",
        "        palabra = token.lower()\n",
        "\n",
        "        # Eliminar tildes (already done in normalice, but keep for robustness)\n",
        "        palabra = unicodedata.normalize('NFD', palabra).encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "        stem = palabra  # Initialize stem with the processed word\n",
        "\n",
        "        # Reglas de lematización (check for irregulars first)\n",
        "        if palabra in lemas_irregulares:\n",
        "            lemma = lemas_irregulares[palabra]\n",
        "            stem = lemma # Use lemma as stem for irregular verbs for simplicity in this function\n",
        "\n",
        "        else:\n",
        "            # Reglas de stemming for regular words\n",
        "            #Retirar sufijo ando\n",
        "            if palabra.endswith(\"ando\") or palabra.endswith(\"iendo\"):\n",
        "                stem = palabra[:-4]\n",
        "            #Retirar sifijo mente\n",
        "            elif palabra.endswith(\"mente\"):\n",
        "                stem = palabra[:-5]\n",
        "            #Retirar sufijo itos e itas\n",
        "            elif palabra.endswith(\"itos\") or palabra.endswith(\"itas\"):\n",
        "                stem = palabra[:-4]\n",
        "            #Retirar isima e isimo\n",
        "            elif palabra.endswith(\"isima\") or palabra.endswith(\"isimo\"):\n",
        "                stem = palabra[:-4]\n",
        "            #Retirar sufijo ito e ita\n",
        "            elif palabra.endswith(\"ito\") or palabra.endswith(\"ita\"):\n",
        "                stem = palabra[:-3]\n",
        "            #Retirar sufijo os y as\n",
        "            elif palabra.endswith(\"os\") or palabra.endswith(\"as\"):\n",
        "                stem = palabra[:-2]\n",
        "            #Retirar sufijo plural es\n",
        "            elif palabra.endswith(\"es\"):\n",
        "                stem = palabra[:-2]\n",
        "            #Retirar sufijo plural s\n",
        "            elif palabra.endswith(\"s\") and len(palabra) > 3:\n",
        "                stem = palabra[:-1]\n",
        "            # No specific rule matched, stem is the lowercased word without accents\n",
        "\n",
        "\n",
        "        resultados.append({\n",
        "            token\n",
        "        })\n",
        "\n",
        "    return resultados\n",
        "\n",
        "\n",
        "# Prueba with a list of normalized tokens\n",
        "normalized_tokens_example = [\"comiendo\", \"gatitos\", \"rapidamente\", \"ponerse\", \"fui\", \"quiero\", \"grandisima\", \"antidemocratica\", \"#hashtag\", \"@user\", \"bogota\"]\n",
        "res = lematizar_y_stem(normalized_tokens_example)\n",
        "\n",
        "for r in res:\n",
        "    print(r)"
      ],
      "metadata": {
        "id": "1uOqQLl67rk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939319f4-cf44-4f4d-f550-061cfd37376b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'comiendo'}\n",
            "{'gatitos'}\n",
            "{'rapidamente'}\n",
            "{'ponerse'}\n",
            "{'fui'}\n",
            "{'quiero'}\n",
            "{'grandisima'}\n",
            "{'antidemocratica'}\n",
            "{'#hashtag'}\n",
            "{'@user'}\n",
            "{'bogota'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lematized_normalized_ES = normalized_result.apply(lematizar_y_stem)\n",
        "print(lematized_normalized_ES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94HcWfrozDRX",
        "outputId": "501ebdb7-6f72-412d-8105-e5b7b7f6176e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      [{#lamadre}, {para}, {esos}, {usuarios}, {de},...\n",
            "1      [{8}, {años}, {de}, {un}, {patio}, {taller}, {...\n",
            "2      [{la}, {@CAR_Cundi}, {de}, {manera}, {antidemo...\n",
            "3      [{@TransMilenio}, {manden}, {buses}, {acaba}, ...\n",
            "4      [{.}, {@Bogota}, {sigue}, {disminuyendo}, {el}...\n",
            "                             ...                        \n",
            "995    [{por}, {fin}, {se}, {transformó}, {😱😱}, {#Ani...\n",
            "996    [{i}, {'m}, {at}, {centro}, {comercial}, {@Par...\n",
            "997    [{2018,}, {gracias}, {💙}, {en}, {bogotá,}, {co...\n",
            "998    [{good}, {morning}, {en}, {bogotá,}, {colombia...\n",
            "999    [{para}, {la}, {señora}, {@MariaFdaCabal}, {lo...\n",
            "Name: text, Length: 1000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lematized_normalized_ES[951]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbnBgcyMxV9d",
        "outputId": "134cb06b-3777-44cd-ce47-49ae885da7e7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ruta'},\n",
              " {'56b'},\n",
              " {'cortijo'},\n",
              " {'↔'},\n",
              " {'chapinero'},\n",
              " {'de'},\n",
              " {'engativa'},\n",
              " {'a'},\n",
              " {'chapinero'},\n",
              " {'(con'},\n",
              " {'mapas)'},\n",
              " {'-'},\n",
              " {'subete'},\n",
              " {'al'},\n",
              " {'#SITP'},\n",
              " {'https://t.co/sm32te5kus'}]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}